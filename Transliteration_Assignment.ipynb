{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11880370,"sourceType":"datasetVersion","datasetId":7466500}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages\n!pip install wandb tqdm seaborn matplotlib\n\n# Import necessary libraries\nimport os\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wandb\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nimport io\nfrom sklearn.model_selection import train_test_split \nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:56:25.380126Z","iopub.execute_input":"2025-05-20T16:56:25.380392Z","iopub.status.idle":"2025-05-20T16:56:33.101396Z","shell.execute_reply.started":"2025-05-20T16:56:25.380372Z","shell.execute_reply":"2025-05-20T16:56:33.100408Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch.nn.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:56:41.970038Z","iopub.execute_input":"2025-05-20T16:56:41.970321Z","iopub.status.idle":"2025-05-20T16:56:41.974195Z","shell.execute_reply.started":"2025-05-20T16:56:41.970298Z","shell.execute_reply":"2025-05-20T16:56:41.973558Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Login to Weights & Biases using Kaggle secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_API_KEY\"] = wandb_api\n\n# Set thread start method for wandb to avoid errors\nos.environ[\"WANDB_START_METHOD\"] = \"thread\"\n\n# Verify login\nwandb.login()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:56:43.299105Z","iopub.execute_input":"2025-05-20T16:56:43.299657Z","iopub.status.idle":"2025-05-20T16:56:50.983455Z","shell.execute_reply.started":"2025-05-20T16:56:43.299631Z","shell.execute_reply":"2025-05-20T16:56:50.982758Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mteja_sai\u001b[0m (\u001b[33mteja_sai-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"class TransliterationDataset(Dataset):\n    \"\"\"Custom Dataset for Transliteration pairs with attestation counts.\"\"\"\n    def __init__(self, source_texts, target_texts, attestation_counts, source_vocab, target_vocab, max_len=50):\n        self.source_texts = source_texts\n        self.target_texts = target_texts\n        self.attestation_counts = attestation_counts  # Added attestation counts\n        self.source_vocab = source_vocab\n        self.target_vocab = target_vocab\n        self.max_len = max_len\n\n        # Get special token indices, assuming they are always present after load_dakshina_data\n        self.pad_idx = self.target_vocab.get('<PAD>', 0)\n        self.unk_idx = self.target_vocab.get('<UNK>', 1)\n        self.sos_idx = self.target_vocab.get('< SOS >', 2)\n        self.eos_idx = self.target_vocab.get('<EOS>', 3)\n\n    def __len__(self):\n        return len(self.source_texts)\n\n    def __getitem__(self, idx):\n        source_text = self.source_texts[idx]\n        target_text = self.target_texts[idx]\n        attestation_count = self.attestation_counts[idx]\n\n        # Convert non-string values to strings safely\n        source_text = str(source_text) if not isinstance(source_text, str) else source_text\n        target_text = str(target_text) if not isinstance(target_text, str) else target_text\n\n        # Convert characters to indices using .get with UNK fallback\n        source_indices = [self.source_vocab.get(char, self.unk_idx) for char in source_text]\n        target_indices = [self.target_vocab.get(char, self.unk_idx) for char in target_text]\n\n        # Add SOS and EOS tokens to target sequence\n        target_indices = [self.sos_idx] + target_indices + [self.eos_idx]\n\n        # Truncate sequences if longer than max_len\n        source_indices = source_indices[:self.max_len]\n        target_indices = target_indices[:self.max_len]\n\n        # Pad sequences to max_len using the PAD index\n        source_indices += [self.pad_idx] * (self.max_len - len(source_indices))\n        target_indices += [self.pad_idx] * (self.max_len - len(target_indices))\n\n        return {\n            'source': torch.tensor(source_indices, dtype=torch.long),\n            'target': torch.tensor(target_indices, dtype=torch.long),\n            'source_text': source_text,\n            'target_text': target_text,\n            'attestation': torch.tensor(attestation_count, dtype=torch.float)  # Added attestation count as tensor\n        }\n\ndef load_dakshina_data(language='ta', base_dir='/kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0', max_len=50):\n    \"\"\"\n    Load data from the Dakshina dataset for a specific language.\n    language: language code (e.g., 'ta' for Tamil)\n    base_dir: base directory containing the dataset structure\n    max_len: maximum sequence length for padding/truncation\n    \"\"\"\n    # Define file paths based on Dakshina dataset structure\n    train_file = os.path.join(base_dir, language, \"lexicons\", f\"{language}.translit.sampled.train.tsv\")\n    dev_file = os.path.join(base_dir, language, \"lexicons\", f\"{language}.translit.sampled.dev.tsv\")\n    test_file = os.path.join(base_dir, language, \"lexicons\", f\"{language}.translit.sampled.test.tsv\")\n    \n    print(f\"Looking for training file at: {train_file}\")\n    \n    # Check if files exist\n    if not os.path.exists(train_file):\n        print(f\"Error: Training file not found at {train_file}\")\n        print(f\"Current working directory: {os.getcwd()}\")\n        print(f\"Files in {os.path.dirname(train_file)} (if directory exists):\")\n        try:\n            if os.path.exists(os.path.dirname(train_file)):\n                print(os.listdir(os.path.dirname(train_file)))\n            else:\n                print(f\"Directory {os.path.dirname(train_file)} does not exist\")\n        except Exception as e:\n            print(f\"Error listing directory: {e}\")\n        \n        # Create a test dataset if the real one can't be found\n        return create_test_dataset(max_len=max_len)\n    \n    # Load data with error handling\n    try:\n        # In Dakshina, the format is: native_script \\t romanization \\t attestation_count\n        # We want source (romanization) -> target (native_script)\n        train_df = pd.read_csv(train_file, sep='\\t', header=None, \n                              names=['target', 'source', 'attestation'], \n                              keep_default_na=False, on_bad_lines='skip')\n        dev_df = pd.read_csv(dev_file, sep='\\t', header=None, \n                            names=['target', 'source', 'attestation'], \n                            keep_default_na=False, on_bad_lines='skip')\n        test_df = pd.read_csv(test_file, sep='\\t', header=None, \n                             names=['target', 'source', 'attestation'], \n                             keep_default_na=False, on_bad_lines='skip')\n\n        # Convert attestation counts to integers\n        train_df['attestation'] = train_df['attestation'].astype(int)\n        dev_df['attestation'] = dev_df['attestation'].astype(int)\n        test_df['attestation'] = test_df['attestation'].astype(int)\n\n        # Convert any non-string values to strings explicitly\n        train_df['source'] = train_df['source'].apply(str)\n        train_df['target'] = train_df['target'].apply(str)\n        dev_df['source'] = dev_df['source'].apply(str)\n        dev_df['target'] = dev_df['target'].apply(str)\n        test_df['source'] = test_df['source'].apply(str)\n        test_df['target'] = test_df['target'].apply(str)\n\n        # Build vocabularies from the training data\n        source_chars = set()\n        target_chars = set()\n\n        for text in train_df['source']:\n            if isinstance(text, str):\n                source_chars.update(text)\n\n        for text in train_df['target']:\n            if isinstance(text, str):\n                target_chars.update(text)\n\n        # Create vocabulary dictionaries with consistent special tokens\n        source_vocab = {}\n        target_vocab = {}\n\n        # Add special tokens first with known indices\n        special_tokens = ['<PAD>', '<UNK>', '< SOS >', '<EOS>']\n        for i, token in enumerate(special_tokens):\n            source_vocab[token] = i\n            target_vocab[token] = i\n\n        # Add sorted unique characters from data\n        for char in sorted(list(source_chars)):\n            if char not in source_vocab:\n                source_vocab[char] = len(source_vocab)\n\n        for char in sorted(list(target_chars)):\n            if char not in target_vocab:\n                target_vocab[char] = len(target_vocab)\n\n        # Print debug information about the vocabularies\n        print(\"Special tokens in vocabulary:\")\n        print(f\"Source vocab keys: {list(source_vocab.keys())[:10]}\")\n        print(f\"Target vocab keys: {list(target_vocab.keys())[:10]}\")\n\n        # Create inverse vocabularies for decoding\n        inv_source_vocab = {v: k for k, v in source_vocab.items()}\n        inv_target_vocab = {v: k for k, v in target_vocab.items()}\n\n        # Create datasets using the loaded data and created vocabs\n        # Include attestation counts in the dataset creation\n        train_dataset = TransliterationDataset(\n            train_df['source'].tolist(),\n            train_df['target'].tolist(),\n            train_df['attestation'].tolist(),  # Pass attestation counts\n            source_vocab,\n            target_vocab,\n            max_len=max_len\n        )\n\n        dev_dataset = TransliterationDataset(\n            dev_df['source'].tolist(),\n            dev_df['target'].tolist(),\n            dev_df['attestation'].tolist(),  # Pass attestation counts\n            source_vocab,\n            target_vocab,\n            max_len=max_len\n        )\n\n        test_dataset = TransliterationDataset(\n            test_df['source'].tolist(),\n            test_df['target'].tolist(),\n            test_df['attestation'].tolist(),  # Pass attestation counts\n            source_vocab,\n            target_vocab,\n            max_len=max_len\n        )\n\n        print(f\"Successfully loaded Dakshina dataset for {language}\")\n        print(f\"Train set: {len(train_dataset)} examples\")\n        print(f\"Dev set: {len(dev_dataset)} examples\")\n        print(f\"Test set: {len(test_dataset)} examples\")\n        print(f\"Source vocabulary size: {len(source_vocab)}\")\n        print(f\"Target vocabulary size: {len(target_vocab)}\")\n        print(f\"Max sequence length: {max_len}\")\n\n        return {\n            'train_dataset': train_dataset,\n            'dev_dataset': dev_dataset,\n            'test_dataset': test_dataset,\n            'source_vocab': source_vocab,\n            'target_vocab': target_vocab,\n            'inv_source_vocab': inv_source_vocab,\n            'inv_target_vocab': inv_target_vocab,\n            'max_len': max_len\n        }\n\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        import traceback\n        traceback.print_exc()\n        return create_test_dataset(max_len=max_len)\n\ndef create_test_dataset(max_len=50):\n    \"\"\"Create a small test dataset for debugging purposes\"\"\"\n    print(\"Creating a minimal test dataset for debugging...\")\n    \n    # Example data with attestation counts\n    source_texts = [\"hello\", \"world\", \"test\", \"longerword\", \"sampledata\", \"another\"]\n    target_texts = [\"ஹலோ\", \"உலகம்\", \"சோதனை\", \"நீண்டசொல்\", \"மாதிரிதரவு\", \"மற்றொன்று\"]\n    attestation_counts = [2, 1, 3, 1, 2, 1]  # Example attestation counts\n\n    # Ensure max_len is at least long enough for the longest example + SOS/EOS\n    min_required_len = max(max(len(s) for s in source_texts), max(len(t) for t in target_texts)) + 2\n    current_max_len = max(max_len, min_required_len)\n    if current_max_len > max_len:\n        print(f\"Warning: Adjusted max_len from {max_len} to {current_max_len} for test data.\")\n        max_len = current_max_len\n\n    source_chars = set(\"\".join(source_texts))\n    target_chars = set(\"\".join(target_texts))\n\n    # Create vocab with consistent special tokens\n    source_vocab = {}\n    target_vocab = {}\n    special_tokens = ['<PAD>', '<UNK>', '< SOS >', '<EOS>']\n    for i, token in enumerate(special_tokens):\n        source_vocab[token] = i\n        target_vocab[token] = i\n\n    for char in sorted(list(source_chars)):\n        if char not in source_vocab:\n            source_vocab[char] = len(source_vocab)\n\n    for char in sorted(list(target_chars)):\n        if char not in target_vocab:\n            target_vocab[char] = len(target_vocab)\n\n    inv_source_vocab = {v: k for k, v in source_vocab.items()}\n    inv_target_vocab = {v: k for k, v in target_vocab.items()}\n\n    # Split into train, dev, test (using fixed small splits)\n    train_src = source_texts[:4]\n    train_tgt = target_texts[:4]\n    train_att = attestation_counts[:4]\n    \n    dev_src = source_texts[4:5]\n    dev_tgt = target_texts[4:5]\n    dev_att = attestation_counts[4:5]\n    \n    test_src = source_texts[5:]\n    test_tgt = target_texts[5:]\n    test_att = attestation_counts[5:]\n\n    train_dataset = TransliterationDataset(train_src, train_tgt, train_att, source_vocab, target_vocab, max_len=max_len)\n    dev_dataset = TransliterationDataset(dev_src, dev_tgt, dev_att, source_vocab, target_vocab, max_len=max_len)\n    test_dataset = TransliterationDataset(test_src, test_tgt, test_att, source_vocab, target_vocab, max_len=max_len)\n\n    print(\"Created minimal test dataset with:\")\n    print(f\"Train set: {len(train_dataset)} examples\")\n    print(f\"Dev set: {len(dev_dataset)} examples\")\n    print(f\"Test set: {len(test_dataset)} examples\")\n    print(f\"Source vocabulary size: {len(source_vocab)}\")\n    print(f\"Target vocabulary size: {len(target_vocab)}\")\n    print(f\"Max sequence length: {max_len}\")\n\n    return {\n        'train_dataset': train_dataset,\n        'dev_dataset': dev_dataset,\n        'test_dataset': test_dataset,\n        'source_vocab': source_vocab,\n        'target_vocab': target_vocab,\n        'inv_source_vocab': inv_source_vocab,\n        'inv_target_vocab': inv_target_vocab,\n        'max_len': max_len\n    }\n\ndef get_dataloaders(data_dict, batch_size=32):\n    \"\"\"Create DataLoaders for train, dev, and test sets\"\"\"\n    train_loader = DataLoader(\n        data_dict['train_dataset'],\n        batch_size=batch_size,\n        shuffle=True,\n    )\n\n    dev_loader = DataLoader(\n        data_dict['dev_dataset'],\n        batch_size=batch_size,\n        shuffle=False,\n    )\n\n    test_loader = DataLoader(\n        data_dict['test_dataset'],\n        batch_size=batch_size,\n        shuffle=False,\n    )\n\n    return train_loader, dev_loader, test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:56:54.500141Z","iopub.execute_input":"2025-05-20T16:56:54.501015Z","iopub.status.idle":"2025-05-20T16:56:54.527266Z","shell.execute_reply.started":"2025-05-20T16:56:54.500989Z","shell.execute_reply":"2025-05-20T16:56:54.526511Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# List files in the input directory\nimport os\nprint(os.listdir(\"/kaggle/input/dakshina-dataset-v1-0-tar\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:08.125088Z","iopub.execute_input":"2025-05-20T16:57:08.125670Z","iopub.status.idle":"2025-05-20T16:57:08.146834Z","shell.execute_reply.started":"2025-05-20T16:57:08.125646Z","shell.execute_reply":"2025-05-20T16:57:08.146250Z"}},"outputs":[{"name":"stdout","text":"['dakshina_dataset_v1.0']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Encoder\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1, cell_type='lstm', dropout=0):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type.lower()\n        \n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        \n        if self.cell_type == 'lstm':\n            self.rnn = nn.LSTM(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        elif self.cell_type == 'gru':\n            self.rnn = nn.GRU(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        else:  # vanilla RNN\n            self.rnn = nn.RNN(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True,\n                nonlinearity='tanh'\n            )\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_length)\n        embedded = self.dropout(self.embedding(x))\n        # embedded shape: (batch_size, seq_length, embedding_size)\n        \n        if self.cell_type == 'lstm':\n            outputs, (hidden, cell) = self.rnn(embedded)\n            return outputs, hidden, cell\n        else:\n            outputs, hidden = self.rnn(embedded)\n            return outputs, hidden, None\n\n# Decoder\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers=1, cell_type='lstm', dropout=0):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type.lower()\n        \n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        \n        if self.cell_type == 'lstm':\n            self.rnn = nn.LSTM(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        elif self.cell_type == 'gru':\n            self.rnn = nn.GRU(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        else:  # vanilla RNN\n            self.rnn = nn.RNN(\n                embedding_size, \n                hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True,\n                nonlinearity='tanh'\n            )\n            \n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, hidden, cell=None):\n        # x shape: (batch_size)\n        x = x.unsqueeze(1)\n        \n        embedded = self.dropout(self.embedding(x))\n        # embedded shape: (batch_size, 1, embedding_size)\n        \n        if self.cell_type == 'lstm':\n            output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n            prediction = self.fc(output.squeeze(1))\n            return prediction, hidden, cell\n        else:\n            output, hidden = self.rnn(embedded, hidden)\n            prediction = self.fc(output.squeeze(1))\n            return prediction, hidden, None\n\n# Attention\nclass Attention(nn.Module):\n    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n        super(Attention, self).__init__()\n        self.attn = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n        self.v = nn.Linear(decoder_hidden_dim, 1, bias=False)\n        \n    def forward(self, hidden, encoder_outputs):\n        # hidden: [batch_size, decoder_hidden_dim]\n        # encoder_outputs: [batch_size, src_len, encoder_hidden_dim]\n        \n        batch_size = encoder_outputs.shape[0]\n        src_len = encoder_outputs.shape[1]\n        \n        # Repeat decoder hidden state src_len times\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n        \n        # Calculate energy\n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n        attention = self.v(energy).squeeze(2)\n        \n        # Get attention weights\n        return F.softmax(attention, dim=1)\n\n# Attention Decoder\nclass AttentionDecoder(nn.Module):\n    def __init__(self, output_size, embedding_size, encoder_hidden_size, decoder_hidden_size, \n                 num_layers=1, cell_type='lstm', dropout=0):\n        super(AttentionDecoder, self).__init__()\n        self.output_size = output_size\n        self.decoder_hidden_size = decoder_hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type.lower()\n        \n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.attention = Attention(encoder_hidden_size, decoder_hidden_size)\n        self.dropout = nn.Dropout(dropout)\n        \n        # Input to the RNN will be embedding + context vector\n        if self.cell_type == 'lstm':\n            self.rnn = nn.LSTM(\n                embedding_size + encoder_hidden_size, \n                decoder_hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        elif self.cell_type == 'gru':\n            self.rnn = nn.GRU(\n                embedding_size + encoder_hidden_size, \n                decoder_hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True\n            )\n        else:  # vanilla RNN\n            self.rnn = nn.RNN(\n                embedding_size + encoder_hidden_size, \n                decoder_hidden_size, \n                num_layers=num_layers, \n                dropout=dropout if num_layers > 1 else 0,\n                batch_first=True,\n                nonlinearity='tanh'\n            )\n            \n        self.fc = nn.Linear(decoder_hidden_size + encoder_hidden_size + embedding_size, output_size)\n    \n    def forward(self, x, hidden, encoder_outputs, cell=None):\n        # x shape: (batch_size)\n        # hidden shape: (num_layers, batch_size, decoder_hidden_size)\n        # encoder_outputs shape: (batch_size, src_len, encoder_hidden_size)\n        \n        x = x.unsqueeze(1)  # (batch_size, 1)\n        embedded = self.dropout(self.embedding(x))  # (batch_size, 1, embedding_size)\n        \n        # Get the last hidden state for attention\n        if self.cell_type == 'lstm':\n            attn_hidden = hidden[-1]\n        else:\n            attn_hidden = hidden[-1]\n            \n        # Calculate attention weights\n        attn_weights = self.attention(attn_hidden, encoder_outputs)  # (batch_size, src_len)\n        \n        # Create context vector by multiplying attention weights with encoder outputs\n        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # (batch_size, 1, encoder_hidden_size)\n        \n        # Combine embedded input and context vector\n        rnn_input = torch.cat((embedded, context), dim=2)  # (batch_size, 1, embedding_size + encoder_hidden_size)\n        \n        # Pass through RNN\n        if self.cell_type == 'lstm':\n            output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n        else:\n            output, hidden = self.rnn(rnn_input, hidden)\n            cell = None\n            \n        # Final output layer\n        # Concatenate output, context and embedded for richer representation\n        output = output.squeeze(1)  # (batch_size, decoder_hidden_size)\n        context = context.squeeze(1)  # (batch_size, encoder_hidden_size)\n        embedded = embedded.squeeze(1)  # (batch_size, embedding_size)\n        \n        prediction = self.fc(torch.cat((output, context, embedded), dim=1))\n        \n        return prediction, hidden, cell, attn_weights\n\n# Seq2Seq\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.cell_type = encoder.cell_type\n        \n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_vocab_size = self.decoder.output_size\n        \n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n        \n        if self.cell_type == 'lstm':\n            encoder_outputs, hidden, cell = self.encoder(source)\n            \n            # Adjust hidden and cell dimensions if encoder and decoder layers differ\n            if self.encoder.num_layers != self.decoder.num_layers:\n                # If encoder has fewer layers than decoder, repeat the layers\n                if self.encoder.num_layers < self.decoder.num_layers:\n                    repeat_factor = self.decoder.num_layers // self.encoder.num_layers\n                    hidden = hidden.repeat(repeat_factor, 1, 1)\n                    cell = cell.repeat(repeat_factor, 1, 1)\n                # If encoder has more layers than decoder, take the last layers\n                else:\n                    hidden = hidden[-self.decoder.num_layers:]\n                    cell = cell[-self.decoder.num_layers:]\n        else:\n            encoder_outputs, hidden, _ = self.encoder(source)\n            cell = None\n            \n            # Adjust hidden dimensions if encoder and decoder layers differ\n            if self.encoder.num_layers != self.decoder.num_layers:\n                # If encoder has fewer layers than decoder, repeat the layers\n                if self.encoder.num_layers < self.decoder.num_layers:\n                    repeat_factor = self.decoder.num_layers // self.encoder.num_layers\n                    hidden = hidden.repeat(repeat_factor, 1, 1)\n                # If encoder has more layers than decoder, take the last layers\n                else:\n                    hidden = hidden[-self.decoder.num_layers:]\n        \n        # First input to the decoder is the < SOS > token\n        decoder_input = target[:, 0]\n        \n        for t in range(1, target_len):\n            if self.cell_type == 'lstm':\n                decoder_output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n            else:\n                decoder_output, hidden, _ = self.decoder(decoder_input, hidden)\n                \n            outputs[:, t, :] = decoder_output\n            \n            # Teacher forcing: use actual target as next input\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = decoder_output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n        \n        return outputs\n\n# AttentionSeq2Seq\nclass AttentionSeq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super(AttentionSeq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.cell_type = encoder.cell_type\n        \n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_vocab_size = self.decoder.output_size\n        src_len = source.shape[1]\n        \n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n        attentions = torch.zeros(batch_size, target_len, src_len).to(self.device)\n        \n        if self.cell_type == 'lstm':\n            encoder_outputs, hidden, cell = self.encoder(source)\n            \n            # Adjust hidden and cell dimensions if encoder and decoder layers differ\n            if self.encoder.num_layers != self.decoder.num_layers:\n                # If encoder has fewer layers than decoder, repeat the layers\n                if self.encoder.num_layers < self.decoder.num_layers:\n                    repeat_factor = self.decoder.num_layers // self.encoder.num_layers\n                    hidden = hidden.repeat(repeat_factor, 1, 1)\n                    cell = cell.repeat(repeat_factor, 1, 1)\n                # If encoder has more layers than decoder, take the last layers\n                else:\n                    hidden = hidden[-self.decoder.num_layers:]\n                    cell = cell[-self.decoder.num_layers:]\n        else:\n            encoder_outputs, hidden, _ = self.encoder(source)\n            cell = None\n            \n            # Adjust hidden dimensions if encoder and decoder layers differ\n            if self.encoder.num_layers != self.decoder.num_layers:\n                # If encoder has fewer layers than decoder, repeat the layers\n                if self.encoder.num_layers < self.decoder.num_layers:\n                    repeat_factor = self.decoder.num_layers // self.encoder.num_layers\n                    hidden = hidden.repeat(repeat_factor, 1, 1)\n                # If encoder has more layers than decoder, take the last layers\n                else:\n                    hidden = hidden[-self.decoder.num_layers:]\n        \n        # First input to the decoder is the < SOS > token\n        decoder_input = target[:, 0]\n        \n        for t in range(1, target_len):\n            if self.cell_type == 'lstm':\n                decoder_output, hidden, cell, attn_weights = self.decoder(\n                    decoder_input, hidden, encoder_outputs, cell\n                )\n            else:\n                decoder_output, hidden, _, attn_weights = self.decoder(\n                    decoder_input, hidden, encoder_outputs\n                )\n                \n            outputs[:, t, :] = decoder_output\n            attentions[:, t, :] = attn_weights\n            \n            # Teacher forcing: use actual target as next input\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = decoder_output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n        \n        return outputs, attentions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:10.217938Z","iopub.execute_input":"2025-05-20T16:57:10.218518Z","iopub.status.idle":"2025-05-20T16:57:10.247042Z","shell.execute_reply.started":"2025-05-20T16:57:10.218476Z","shell.execute_reply":"2025-05-20T16:57:10.246312Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def init_weights(m):\n    \"\"\"Initializes model weights.\"\"\"\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        elif 'bias' in name:\n            nn.init.constant_(param.data, 0)\n\ndef count_parameters(model):\n    \"\"\"Counts the number of trainable parameters in a model.\"\"\"\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef train_epoch(model, iterator, optimizer, criterion, clip, device, teacher_forcing_ratio=0.5):\n    \"\"\"\n    Trains the model for one epoch.\n    Uses attestation counts as weights for the loss function.\n    \"\"\"\n    model.train()\n    epoch_loss = 0\n\n    for batch in tqdm(iterator, desc=\"Training\"):\n        src = batch['source'].to(device)\n        trg = batch['target'].to(device)\n        attestation = batch['attestation'].to(device)  # Get attestation counts\n        \n        optimizer.zero_grad()\n        \n        if isinstance(model, AttentionSeq2Seq):\n            output, _ = model(src, trg, teacher_forcing_ratio)\n        else:\n            output = model(src, trg, teacher_forcing_ratio)\n\n        output_dim = output.shape[-1]\n\n        # Slice the output and target to remove the first timestep\n        output_seq = output[:, 1:, :]\n        trg_seq = trg[:, 1:]\n        \n        # Check for empty sequences after slicing\n        if trg_seq.numel() == 0:\n            continue\n\n        # Calculate unweighted loss\n        loss = criterion(output_seq.reshape(-1, output_dim), trg_seq.reshape(-1))\n        \n        # Apply attestation weights to the loss\n        seq_len = trg_seq.shape[1]\n        attestation_weights = attestation.repeat_interleave(seq_len)\n        \n        # Normalize weights to sum to batch size\n        attestation_weights = attestation_weights * (attestation_weights.size(0) / attestation_weights.sum())\n        \n        # Apply weights to loss\n        weighted_loss = (loss * attestation_weights).mean()\n        \n        weighted_loss.backward()\n        \n        # Clip gradients to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        epoch_loss += weighted_loss.item()\n\n    return epoch_loss / len(iterator) if len(iterator) > 0 else 0.0\n\ndef evaluate(model, iterator, criterion, device):\n    \"\"\"\n    Evaluates the model on a given dataset iterator.\n    Calculates average loss over the dataset, using attestation counts as weights.\n    \"\"\"\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for batch in tqdm(iterator, desc=\"Evaluating Loss\"):\n            src = batch['source'].to(device)\n            trg = batch['target'].to(device)\n            attestation = batch['attestation'].to(device)  # Get attestation counts\n\n            # Pass source and target to the model\n            if isinstance(model, AttentionSeq2Seq):\n                output, _ = model(src, trg, 0)\n            else:\n                output = model(src, trg, 0)\n\n            output_dim = output.shape[-1]\n\n            # Slice the output and target to remove the first timestep (SOS)\n            output_seq = output[:, 1:, :]\n            trg_seq = trg[:, 1:]\n\n            # Check for empty sequences after slicing\n            if trg_seq.numel() == 0:\n                continue\n\n            # Calculate unweighted loss\n            loss = criterion(output_seq.reshape(-1, output_dim), trg_seq.reshape(-1))\n            \n            # Apply attestation weights to the loss\n            seq_len = trg_seq.shape[1]\n            attestation_weights = attestation.repeat_interleave(seq_len)\n            \n            # Normalize weights to sum to batch size\n            attestation_weights = attestation_weights * (attestation_weights.size(0) / attestation_weights.sum())\n            \n            # Apply weights to loss\n            weighted_loss = (loss * attestation_weights).mean()\n            \n            epoch_loss += weighted_loss.item()\n\n    return epoch_loss / len(iterator) if len(iterator) > 0 else 0.0\n\ndef calculate_accuracy(model, iterator, inv_target_vocab, device):\n    \"\"\"\n    Calculates word-level accuracy (exact match) and generates predictions.\n    Performs greedy decoding step-by-step.\n    Includes attestation counts in the predictions.\n    \"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    predictions = []\n\n    # Get special token indices using .get() with fallbacks\n    target_vocab = {v: k for k, v in inv_target_vocab.items()}\n    \n    # Try different possible token names for special tokens\n    sos_idx = None\n    for token in ['< SOS >', '< SOS >', 'SOS']:\n        if token in target_vocab:\n            sos_idx = target_vocab[token]\n            break\n    if sos_idx is None:\n        sos_idx = 2  # Default SOS index\n        \n    eos_idx = None\n    for token in ['<EOS>', '< EOS >', 'EOS']:\n        if token in target_vocab:\n            eos_idx = target_vocab[token]\n            break\n    if eos_idx is None:\n        eos_idx = 3  # Default EOS index\n        \n    pad_idx = target_vocab.get('<PAD>', 0)\n    unk_idx = target_vocab.get('<UNK>', 1)\n\n    # Determine maximum prediction length\n    max_prediction_length = getattr(iterator.dataset, 'max_len', 50)\n    if max_prediction_length < 10:\n        max_prediction_length = 50\n\n    with torch.no_grad():\n        for batch in tqdm(iterator, desc=\"Calculating Accuracy\"):\n            src = batch['source'].to(device)\n            trg_texts = batch['target_text']\n            attestation_counts = batch['attestation']  # Get attestation counts\n\n            # Get the actual batch size for the current batch\n            current_batch_size = src.shape[0]\n\n            # Handle empty batches gracefully\n            if current_batch_size == 0:\n                continue\n\n            # --- Encoder Step ---\n            if hasattr(model, 'cell_type') and model.cell_type == 'lstm':\n                encoder_outputs, hidden, cell = model.encoder(src)\n            else:\n                encoder_outputs, hidden, _ = model.encoder(src)\n                cell = None\n\n            # --- Decoder Step-by-Step Decoding (Greedy Search) ---\n            decoder_input = torch.full((current_batch_size,), sos_idx, dtype=torch.long, device=device)\n\n            batch_decoded_indices = [[] for _ in range(current_batch_size)]\n            finished_decoding = [False] * current_batch_size\n            \n            # For storing attention weights if using attention model\n            batch_attention_weights = [[] for _ in range(current_batch_size)] if isinstance(model, AttentionSeq2Seq) else None\n\n            for t in range(max_prediction_length):\n                if isinstance(model, AttentionSeq2Seq):\n                    if hasattr(model, 'cell_type') and model.cell_type == 'lstm':\n                        decoder_output, hidden, cell, attn_weights = model.decoder(\n                            decoder_input, hidden, encoder_outputs, cell\n                        )\n                    else:\n                        decoder_output, hidden, _, attn_weights = model.decoder(\n                            decoder_input, hidden, encoder_outputs\n                        )\n                else:\n                    if hasattr(model, 'cell_type') and model.cell_type == 'lstm':\n                        decoder_output, hidden, cell = model.decoder(\n                            decoder_input, hidden, cell\n                        )\n                    else:\n                        decoder_output, hidden, _ = model.decoder(\n                            decoder_input, hidden\n                        )\n\n                # Get the predicted token index for this step\n                top1 = decoder_output.argmax(1)\n                \n                # Update decoded indices and finished status for each sequence in the batch\n                for i in range(current_batch_size):\n                    if not finished_decoding[i]:\n                        predicted_token_idx = top1[i].item()\n                        batch_decoded_indices[i].append(predicted_token_idx)\n                        \n                        # Store attention weights if using attention model\n                        if isinstance(model, AttentionSeq2Seq):\n                            batch_attention_weights[i].append(attn_weights[i].cpu().numpy())\n\n                        # Check for EOS\n                        if predicted_token_idx == eos_idx:\n                            finished_decoding[i] = True\n\n                # The input for the *next* step is the tokens predicted in this step\n                decoder_input = top1\n\n                # Stop early if all sequences have finished decoding\n                if all(finished_decoding):\n                    break\n\n            # --- Post-process decoded indices to get predicted strings ---\n            for i in range(current_batch_size):\n                pred_chars = []\n                for idx in batch_decoded_indices[i]:\n                    if idx == eos_idx:\n                        break\n                    if idx != pad_idx and idx != unk_idx:\n                        pred_char = inv_target_vocab.get(idx, None)\n                        if pred_char is not None and pred_char not in ['<PAD>', '<UNK>', '< SOS >', '<EOS>', '< SOS >']:\n                            pred_chars.append(pred_char)\n\n                pred_text = ''.join(pred_chars)\n                original_target_text = trg_texts[i]\n                is_correct = (pred_text == original_target_text)\n                \n                if is_correct:\n                    correct += 1\n                total += 1\n\n                # Store prediction details with attestation count\n                prediction_info = {\n                    'source': batch['source_text'][i],\n                    'target': batch['target_text'][i],\n                    'prediction': pred_text,\n                    'correct': is_correct,\n                    'attestation': attestation_counts[i].item()  # Include attestation count\n                }\n                \n                # Add attention weights if available\n                if isinstance(model, AttentionSeq2Seq):\n                    prediction_info['attention_weights'] = batch_attention_weights[i]\n                \n                predictions.append(prediction_info)\n\n    accuracy = correct / total if total > 0 else 0.0\n    return accuracy, predictions\n\ndef epoch_time(start_time, end_time):\n    \"\"\"Calculates elapsed time in minutes and seconds.\"\"\"\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:21.247040Z","iopub.execute_input":"2025-05-20T16:57:21.247669Z","iopub.status.idle":"2025-05-20T16:57:21.269216Z","shell.execute_reply.started":"2025-05-20T16:57:21.247646Z","shell.execute_reply":"2025-05-20T16:57:21.268392Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train_model(config=None):\n    \"\"\"\n    Main training function with descriptive run names.\n    \"\"\"\n    # Generate a descriptive run name\n    run_name = None\n    if config:\n        # Model type\n        model_type = \"attention\" if getattr(config, 'use_attention', False) else \"vanilla\"\n        \n        # Cell type\n        cell_type = getattr(config, 'cell_type', 'lstm')\n        \n        # Architecture details\n        emb_size = getattr(config, 'embedding_size', 64)\n        hid_size = getattr(config, 'hidden_size', 128)\n        \n        # Layer information\n        num_layers = getattr(config, 'num_layers', 1)\n        \n        # Training parameters\n        optimizer_name = getattr(config, 'optimizer', 'adam')\n        lr = getattr(config, 'learning_rate', 0.001)\n        dropout = getattr(config, 'dropout', 0.0)\n        batch_size = getattr(config, 'batch_size', 64)\n        \n        # Create meaningful run name\n        run_name = f\"{model_type}_{cell_type}_emb{emb_size}_hid{hid_size}_layers{num_layers}_drop{dropout}_{optimizer_name}_lr{lr:.6f}_batch{batch_size}\"\n        print(f\"Generated run name: {run_name}\")\n    \n    # Set thread start method for wandb\n    os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n    \n    # Initialize wandb with the descriptive run name - IMPORTANT: Don't use with statement\n    wandb_run = wandb.init(project=\"transliteration-seq2seq\", config=config, name=run_name, settings=wandb.Settings(start_method=\"thread\"))\n    print(f\"Actual wandb run name: {wandb_run.name}\")\n    \n    config = wandb.config\n\n    print(f\"Starting training run with config: {config}\")\n\n    # --- Data Loading ---\n    data_dict = load_dakshina_data(\n        language=config.language,\n        base_dir=DATA_DIR,\n        max_len=getattr(config, 'max_seq_len', 50)\n    )\n\n    # Handle potential data loading failure\n    if data_dict is None or not data_dict['train_dataset'] or len(data_dict['train_dataset']) < config.batch_size:\n        print(\"Failed to load data or train dataset is too small. Exiting training.\")\n        if wandb.run:\n             wandb.log({\"train_loss\": float('nan'), \"valid_loss\": float('nan'), \"valid_accuracy\": 0.0, \"test_accuracy\": 0.0})\n             wandb.run.finish(exit_code=1)\n        return None, 0, []\n\n    train_loader, dev_loader, test_loader = get_dataloaders(\n        data_dict,\n        batch_size=config.batch_size\n    )\n\n    # Set device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    # --- Model Creation ---\n    input_size = len(data_dict['source_vocab'])\n    output_size = len(data_dict['target_vocab'])\n    pad_idx = data_dict['target_vocab'].get('<PAD>', 0)\n\n    # Get number of layers\n    num_layers = getattr(config, 'num_layers', 1)\n\n    # Create encoder\n    encoder = Encoder(\n        input_size=input_size,\n        embedding_size=config.embedding_size,\n        hidden_size=config.hidden_size,\n        num_layers=num_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    ).to(device)\n\n    # Create decoder (Attention or Vanilla)\n    if config.use_attention:\n        decoder = AttentionDecoder(\n            output_size=output_size,\n            embedding_size=config.embedding_size,\n            encoder_hidden_size=config.hidden_size,\n            decoder_hidden_size=config.hidden_size,\n            num_layers=num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout\n        ).to(device)\n        model = AttentionSeq2Seq(encoder, decoder, device).to(device)\n    else:\n        decoder = Decoder(\n            output_size=output_size,\n            embedding_size=config.embedding_size,\n            hidden_size=config.hidden_size,\n            num_layers=num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout\n        ).to(device)\n        model = Seq2Seq(encoder, decoder, device).to(device)\n\n    # Initialize weights\n    model.apply(init_weights)\n\n    # Print model info\n    print(f'The model has {count_parameters(model):,} trainable parameters')\n    wandb.log({\"trainable_parameters\": count_parameters(model)})\n\n    # Define optimizer and criterion\n    optimizer_name = getattr(config, 'optimizer', 'adam').lower()\n    \n    if optimizer_name == 'adam':\n        optimizer = optim.Adam(\n            model.parameters(), \n            lr=config.learning_rate,\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    elif optimizer_name == 'rmsprop':\n        optimizer = optim.RMSprop(\n            model.parameters(), \n            lr=config.learning_rate,\n            alpha=getattr(config, 'rmsprop_alpha', 0.99),\n            eps=getattr(config, 'rmsprop_eps', 1e-8),\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    elif optimizer_name == 'sgd':\n        optimizer = optim.SGD(\n            model.parameters(), \n            lr=config.learning_rate,\n            momentum=getattr(config, 'momentum', 0),\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    else:\n        print(f\"Warning: Unknown optimizer '{optimizer_name}'. Using Adam.\")\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n    \n    # Log the optimizer type\n    wandb.log({\"optimizer_type\": optimizer_name})\n    \n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx, reduction='none')  # Use 'none' to apply attestation weights\n\n    # --- Learning Rate Scheduler ---\n    scheduler_name = getattr(config, 'scheduler', 'none').lower()\n    scheduler = None\n    \n    if scheduler_name == 'plateau':\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, \n            mode='min', \n            factor=getattr(config, 'scheduler_factor', 0.1),\n            patience=getattr(config, 'scheduler_patience', 10),\n            verbose=True\n        )\n    elif scheduler_name == 'cosine':\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=getattr(config, 'scheduler_t_max', config.n_epochs),\n            eta_min=getattr(config, 'scheduler_eta_min', 0)\n        )\n    elif scheduler_name != 'none':\n        print(f\"Warning: Unknown scheduler '{scheduler_name}'. Not using a scheduler.\")\n\n    # --- Training Loop ---\n    best_valid_loss = float('inf')\n    best_valid_accuracy = 0.0\n\n    for epoch in range(config.n_epochs):\n        start_time = time.time()\n\n        train_loss = train_epoch(\n            model,\n            train_loader,\n            optimizer,\n            criterion,\n            config.clip,\n            device,\n            config.teacher_forcing_ratio\n        )\n\n        # Evaluate on development set\n        valid_loss = evaluate(model, dev_loader, criterion, device)\n\n        # Calculate accuracy on validation set\n        valid_accuracy, _ = calculate_accuracy(\n            model,\n            dev_loader,\n            data_dict['inv_target_vocab'],\n            device\n        )\n\n        end_time = time.time()\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n        # Step the scheduler if using one\n        if scheduler is not None:\n            if scheduler_name == 'plateau':\n                scheduler.step(valid_loss)\n            else:\n                scheduler.step()\n        \n        # Get current learning rate\n        current_lr = optimizer.param_groups[0]['lr']\n\n        # Log epoch metrics to wandb\n        wandb.log({\n            \"train_loss\": train_loss,\n            \"valid_loss\": valid_loss,\n            \"valid_accuracy\": valid_accuracy,\n            \"epoch\": epoch,\n            \"epoch_time_min\": epoch_mins,\n            \"epoch_time_sec\": epoch_secs,\n            \"learning_rate\": current_lr\n            })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:30.050652Z","iopub.execute_input":"2025-05-20T16:57:30.051162Z","iopub.status.idle":"2025-05-20T16:57:30.068101Z","shell.execute_reply.started":"2025-05-20T16:57:30.051143Z","shell.execute_reply":"2025-05-20T16:57:30.067455Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_model(config=None): \n    \"\"\"\n    Main training function with descriptive run names.\n    \"\"\"\n    # Generate a descriptive run name\n    run_name = None\n    if config:\n        # Model type\n        model_type = \"attention\" if getattr(config, 'use_attention', False) else \"vanilla\"\n        \n        # Cell type\n        cell_type = getattr(config, 'cell_type', 'lstm')\n        \n        # Architecture details\n        emb_size = getattr(config, 'embedding_size', 64)\n        hid_size = getattr(config, 'hidden_size', 128)\n        \n        # Layer information\n        num_layers = getattr(config, 'num_layers', 1)\n        \n        # Training parameters\n        optimizer_name = getattr(config, 'optimizer', 'adam')\n        lr = getattr(config, 'learning_rate', 0.001)\n        dropout = getattr(config, 'dropout', 0.0)\n        batch_size = getattr(config, 'batch_size', 64)\n        \n        # Create meaningful run name\n        run_name = f\"{model_type}_{cell_type}_emb{emb_size}_hid{hid_size}_layers{num_layers}_drop{dropout}_{optimizer_name}_lr{lr:.6f}_batch{batch_size}\"\n        print(f\"Generated run name: {run_name}\")\n    \n    # Set thread start method for wandb\n    os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n    \n    wandb_run = wandb.init(project=\"transliteration-seq2seq\", config=config, settings=wandb.Settings(start_method=\"thread\"))\n\n    # Override run name for sweep\n    if run_name and wandb.run:\n        wandb.run.name = run_name\n        wandb.run.save()\n    \n    print(f\"Actual wandb run name: {wandb.run.name}\")\n\n    config = wandb.config\n\n    print(f\"Starting training run with config: {config}\")\n\n    # --- Data Loading ---\n    data_dict = load_dakshina_data(\n        language=config.language,\n        base_dir=DATA_DIR,\n        max_len=getattr(config, 'max_seq_len', 50)\n    )\n\n    # Handle potential data loading failure\n    if data_dict is None or not data_dict['train_dataset'] or len(data_dict['train_dataset']) < config.batch_size:\n        print(\"Failed to load data or train dataset is too small. Exiting training.\")\n        if wandb.run:\n             wandb.log({\"train_loss\": float('nan'), \"valid_loss\": float('nan'), \"valid_accuracy\": 0.0, \"test_accuracy\": 0.0})\n             wandb.run.finish(exit_code=1)\n        return None, 0, []\n\n    train_loader, dev_loader, test_loader = get_dataloaders(\n        data_dict,\n        batch_size=config.batch_size\n    )\n\n    # Set device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    # --- Model Creation ---\n    input_size = len(data_dict['source_vocab'])\n    output_size = len(data_dict['target_vocab'])\n    pad_idx = data_dict['target_vocab'].get('<PAD>', 0)\n\n    # Get number of layers\n    num_layers = getattr(config, 'num_layers', 1)\n\n    # Create encoder\n    encoder = Encoder(\n        input_size=input_size,\n        embedding_size=config.embedding_size,\n        hidden_size=config.hidden_size,\n        num_layers=num_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    ).to(device)\n\n    # Create decoder (Attention or Vanilla)\n    if config.use_attention:\n        decoder = AttentionDecoder(\n            output_size=output_size,\n            embedding_size=config.embedding_size,\n            encoder_hidden_size=config.hidden_size,\n            decoder_hidden_size=config.hidden_size,\n            num_layers=num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout\n        ).to(device)\n        model = AttentionSeq2Seq(encoder, decoder, device).to(device)\n    else:\n        decoder = Decoder(\n            output_size=output_size,\n            embedding_size=config.embedding_size,\n            hidden_size=config.hidden_size,\n            num_layers=num_layers,\n            cell_type=config.cell_type,\n            dropout=config.dropout\n        ).to(device)\n        model = Seq2Seq(encoder, decoder, device).to(device)\n\n    # Initialize weights\n    model.apply(init_weights)\n\n    # Print model info\n    print(f'The model has {count_parameters(model):,} trainable parameters')\n    wandb.log({\"trainable_parameters\": count_parameters(model)})\n\n    # Define optimizer and criterion\n    optimizer_name = getattr(config, 'optimizer', 'adam').lower()\n    \n    if optimizer_name == 'adam':\n        optimizer = optim.Adam(\n            model.parameters(), \n            lr=config.learning_rate,\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    elif optimizer_name == 'rmsprop':\n        optimizer = optim.RMSprop(\n            model.parameters(), \n            lr=config.learning_rate,\n            alpha=getattr(config, 'rmsprop_alpha', 0.99),\n            eps=getattr(config, 'rmsprop_eps', 1e-8),\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    elif optimizer_name == 'sgd':\n        optimizer = optim.SGD(\n            model.parameters(), \n            lr=config.learning_rate,\n            momentum=getattr(config, 'momentum', 0),\n            weight_decay=getattr(config, 'weight_decay', 0)\n        )\n    else:\n        print(f\"Warning: Unknown optimizer '{optimizer_name}'. Using Adam.\")\n        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n    \n    # Log the optimizer type\n    wandb.log({\"optimizer_type\": optimizer_name})\n    \n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx, reduction='none')  # Use 'none' to apply attestation weights\n\n    # --- Learning Rate Scheduler ---\n    scheduler_name = getattr(config, 'scheduler', 'none').lower()\n    scheduler = None\n    \n    if scheduler_name == 'plateau':\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, \n            mode='min', \n            factor=getattr(config, 'scheduler_factor', 0.1),\n            patience=getattr(config, 'scheduler_patience', 10),\n            verbose=True\n        )\n    elif scheduler_name == 'cosine':\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=getattr(config, 'scheduler_t_max', config.n_epochs),\n            eta_min=getattr(config, 'scheduler_eta_min', 0)\n        )\n    elif scheduler_name != 'none':\n        print(f\"Warning: Unknown scheduler '{scheduler_name}'. Not using a scheduler.\")\n\n    # --- Training Loop ---\n    best_valid_loss = float('inf')\n    best_valid_accuracy = 0.0\n\n    for epoch in range(config.n_epochs):\n        start_time = time.time()\n\n        train_loss = train_epoch(\n            model,\n            train_loader,\n            optimizer,\n            criterion,\n            config.clip,\n            device,\n            config.teacher_forcing_ratio\n        )\n\n        # Evaluate on development set\n        valid_loss = evaluate(model, dev_loader, criterion, device)\n\n        # Calculate accuracy on validation set\n        valid_accuracy, _ = calculate_accuracy(\n            model,\n            dev_loader,\n            data_dict['inv_target_vocab'],\n            device\n        )\n\n        end_time = time.time()\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n        # Step the scheduler if using one\n        if scheduler is not None:\n            if scheduler_name == 'plateau':\n                scheduler.step(valid_loss)\n            else:\n                scheduler.step()\n        \n        # Get current learning rate\n        current_lr = optimizer.param_groups[0]['lr']\n\n        # Log epoch metrics to wandb\n        wandb.log({\n            \"train_loss\": train_loss,\n            \"valid_loss\": valid_loss,\n            \"valid_accuracy\": valid_accuracy,\n            \"epoch\": epoch,\n            \"epoch_time_min\": epoch_mins,\n            \"epoch_time_sec\": epoch_secs,\n            \"learning_rate\": current_lr\n        })\n\n        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n        print(f'\\tTrain Loss: {train_loss:.4f}')\n        print(f'\\t Val. Loss: {valid_loss:.4f}')\n        print(f'\\t Val. Accuracy: {valid_accuracy:.4f}')\n        print(f'\\t Learning Rate: {current_lr:.6f}')\n\n        # Save the best model based on validation loss\n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            best_valid_accuracy = valid_accuracy\n            model_save_path = f'best-model-{wandb.run.id}.pt'\n            torch.save(model.state_dict(), model_save_path)\n            print(f\"Saved new best model to {model_save_path}\")\n\n    print(\"Training finished.\")\n\n    # --- Final Evaluation on Test Set ---\n    print(\"Evaluating best model on test set...\")\n    model_save_path = f'best-model-{wandb.run.id}.pt'\n    if os.path.exists(model_save_path):\n         model.to(device)\n         model.load_state_dict(torch.load(model_save_path, map_location=device))\n         model.eval()\n\n         # Calculate test loss\n         test_loss = evaluate(model, test_loader, criterion, device)\n\n         # Calculate test accuracy and get predictions\n         test_accuracy, test_predictions = calculate_accuracy(\n             model,\n             test_loader,\n             data_dict['inv_target_vocab'],\n             device\n         )\n\n         # Log final test metrics\n         if wandb.run:\n             wandb.log({\n                 \"test_loss\": test_loss,\n                 \"test_accuracy\": test_accuracy\n             })\n             print(f'Test Loss: {test_loss:.4f}')\n             print(f'Test Accuracy: {test_accuracy:.4f}')\n\n             # --- Save Predictions ---\n             folder_name = 'predictions/vanilla'\n             if config.use_attention:\n                 folder_name = 'predictions/attention'\n\n             os.makedirs(folder_name, exist_ok=True)\n\n             predictions_file_path = f'{folder_name}/predictions-{wandb.run.id}.json'\n             with open(predictions_file_path, 'w', encoding='utf-8') as f:\n                 # Include attestation counts in the saved predictions\n                 serializable_predictions = []\n                 for i, p in enumerate(test_predictions):\n                      serializable_prediction = {\n                           'source': p['source'],\n                           'target': p['target'],\n                           'prediction': p['prediction'],\n                           'correct': bool(p['correct']),\n                           'attestation': float(p['attestation'])\n                      }\n                      \n                      # Include attention weights if available\n                      if 'attention_weights' in p:\n                          serializable_prediction['attention_weights'] = [weights.tolist() for weights in p['attention_weights']]\n                          \n                      serializable_predictions.append(serializable_prediction)\n                      \n                 json.dump(serializable_predictions, f, ensure_ascii=False, indent=2)\n             print(f\"Saved predictions to {predictions_file_path}\")\n\n             wandb.run.finish()\n         return model, test_accuracy, test_predictions\n    else:\n         print(f\"Best model file {model_save_path} not found. Cannot perform test evaluation.\")\n         if wandb.run and wandb.run.state == 'running':\n              if wandb.run.summary.get(\"test_accuracy\") is None:\n                  wandb.log({\"test_loss\": float('nan'), \"test_accuracy\": 0.0})\n              wandb.run.finish(exit_code=1)\n         return None, 0, []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:35.974905Z","iopub.execute_input":"2025-05-20T16:57:35.975444Z","iopub.status.idle":"2025-05-20T16:57:35.997045Z","shell.execute_reply.started":"2025-05-20T16:57:35.975423Z","shell.execute_reply":"2025-05-20T16:57:35.996281Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"LANGUAGE = 'ta'\nDATA_DIR = '/kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:57:42.649839Z","iopub.execute_input":"2025-05-20T16:57:42.650334Z","iopub.status.idle":"2025-05-20T16:57:42.653776Z","shell.execute_reply.started":"2025-05-20T16:57:42.650313Z","shell.execute_reply":"2025-05-20T16:57:42.653156Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def run_sweep(sweep_config: dict, count: int = 50):\n    \"\"\"\n    Runs a wandb hyperparameter sweep.\n    \"\"\"\n    # Set thread start method for wandb\n    os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n    \n    # Add project name to sweep_config\n    sweep_config['project'] = \"transliteration-seq2seq\"\n    \n    print(f\"Creating sweep with configuration: {sweep_config['method']}\")\n    sweep_id = wandb.sweep(\n        sweep_config\n    )\n    print(f\"Starting sweep with ID: {sweep_id}\")\n    print(f\"Running {count} trials.\")\n    wandb.agent(sweep_id, train_model, count=count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:21:40.188501Z","iopub.execute_input":"2025-05-20T16:21:40.189191Z","iopub.status.idle":"2025-05-20T16:21:40.193440Z","shell.execute_reply.started":"2025-05-20T16:21:40.189168Z","shell.execute_reply":"2025-05-20T16:21:40.192644Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"vanilla_sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'valid_accuracy', 'goal': 'maximize'},\n    'parameters': {\n    # Fixed parameters for the sweep\n    'language': {'value': LANGUAGE},\n    'data_dir': {'value': DATA_DIR},\n    'max_seq_len': {'value': 50},\n    'use_attention': {'value': False},\n        # Model architecture parameters\n    'embedding_size': {'values': 64, 128, 256},\n    'hidden_size': {'values': 64, 128, 256},\n    'num_layers': {'values': 3, 2, 1, 4, 5},  # Same number of layers for encoder and decoder\n    'cell_type': {'values': ['rnn', 'lstm', 'gru']},\n    'dropout': {'values': [0.0, 0.2, 0.3]},\n    \n    # Optimizer parameters\n    'optimizer': {'values': ['adam', 'rmsprop', 'sgd']},\n    'learning_rate': {'distribution': 'log_uniform_values', 'min': 0.0001, 'max': 0.01},\n    'weight_decay': {'values': [0, 0.0001, 0.001]},\n    \n    # Optimizer-specific parameters\n    'rmsprop_alpha': {'value': 0.99},\n    'momentum': {'values': [0, 0.9]},  # For SGD\n    \n    # Learning rate scheduler\n    'scheduler': {'values': ['none', 'plateau', 'cosine']},\n    'scheduler_factor': {'value': 0.5},  # For plateau\n    'scheduler_patience': {'value': 5},  # For plateau\n    'scheduler_t_max': {'value': 10},    # For cosine\n    \n    # Training parameters\n    'batch_size': {'values': },\n    'n_epochs': {'value': 10},  # 10 epochs per run\n    'clip': {'value': 1.0},\n    'teacher_forcing_ratio': {'values': [0.5, 0.7]}\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:09:17.235550Z","iopub.execute_input":"2025-05-20T16:09:17.236211Z","iopub.status.idle":"2025-05-20T16:09:17.242565Z","shell.execute_reply.started":"2025-05-20T16:09:17.236189Z","shell.execute_reply":"2025-05-20T16:09:17.241633Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_35/219011122.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    'embedding_size': {'values': 64, 128, 256},\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"],"ename":"SyntaxError","evalue":"':' expected after dictionary key (219011122.py, line 11)","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"def run_sweep(sweep_config: dict, count: int = 50):\n    \"\"\"\n    Runs a wandb hyperparameter sweep.\n    \"\"\"\n    # Set thread start method for wandb\n    os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n    \n    # Add project name to sweep_config\n    sweep_config['project'] = \"transliteration-seq2seq\"\n    \n    print(f\"Creating sweep with configuration: {sweep_config['method']}\")\n    sweep_id = wandb.sweep(\n        sweep_config\n    )\n    print(f\"Starting sweep with ID: {sweep_id}\")\n    print(f\"Running {count} trials.\")\n    wandb.agent(sweep_id, train_model, count=count)\n\n# Define sweep configuration for vanilla model (no attention)\nvanilla_sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'valid_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        # Fixed parameters for the sweep\n        'language': {'value': LANGUAGE},\n        'data_dir': {'value': DATA_DIR},\n        'max_seq_len': {'value': 50},\n        'use_attention': {'value': False},\n        \n        # Model architecture parameters\n        'embedding_size': {'values': [128, 64, 32]},\n        'hidden_size': {'values': [256, 128, 64]},\n        'num_layers': {'values': [4, 3, 2, 1]},  # Same number of layers for encoder and decoder\n        'cell_type': {'values': ['lstm', 'gru', 'rnn']},\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n        \n        # Optimizer parameters\n        'optimizer': {'values': ['adam', 'rmsprop', 'sgd']},\n        'learning_rate': {'distribution': 'log_uniform_values', 'min': 0.0001, 'max': 0.01},\n        'weight_decay': {'values': [0, 0.0001, 0.001]},\n        \n        # Optimizer-specific parameters\n        'rmsprop_alpha': {'value': 0.99},\n        'momentum': {'values': [0, 0.9]},  # For SGD\n        \n        # Learning rate scheduler\n        'scheduler': {'values': ['none', 'plateau', 'cosine']},\n        'scheduler_factor': {'value': 0.5},  # For plateau\n        'scheduler_patience': {'value': 5},  # For plateau\n        'scheduler_t_max': {'value': 10},    # For cosine\n        \n        # Training parameters\n        'batch_size': {'values': [32, 64, 128]},\n        'n_epochs': {'value': 10},  # 10 epochs per run\n        'clip': {'value': 1.0},\n        'teacher_forcing_ratio': {'values': [0.5, 0.7]}\n    }\n}\n\n# Define sweep configuration for attention model\nattention_sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'valid_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        # Fixed parameters for the sweep\n        'language': {'value': LANGUAGE},\n        'data_dir': {'value': DATA_DIR},\n        'max_seq_len': {'value': 50},\n        'use_attention': {'value': True},\n        \n        # Model architecture parameters\n        'embedding_size': {'values': [128, 64, 32]},\n        'hidden_size': {'values': [256, 128, 64]},\n        'num_layers': {'values': [4, 3, 2, 1]},  # Same number of layers for encoder and decoder\n        'cell_type': {'values': ['lstm', 'gru', 'rnn']},\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n        \n        # Optimizer parameters\n        'optimizer': {'values': ['adam', 'rmsprop', 'sgd']},\n        'learning_rate': {'distribution': 'log_uniform_values', 'min': 0.0001, 'max': 0.01},\n        'weight_decay': {'values': [0, 0.0001, 0.001]},\n        \n        # Optimizer-specific parameters\n        'rmsprop_alpha': {'value': 0.99},\n        'momentum': {'values': [0, 0.9]},  # For SGD\n        \n        # Learning rate scheduler\n        'scheduler': {'values': ['none', 'plateau', 'cosine']},\n        'scheduler_factor': {'value': 0.5},  # For plateau\n        'scheduler_patience': {'value': 5},  # For plateau\n        'scheduler_t_max': {'value': 10},    # For cosine\n        \n        # Training parameters\n        'batch_size': {'values': [32, 64, 128]},\n        'n_epochs': {'value': 10},  # 10 epochs per run\n        'clip': {'value': 1.0},\n        'teacher_forcing_ratio': {'values': [0.5, 0.7]}\n    }\n}\n\n# Set the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Check for GPU availability\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n    # Set CUDA flags for better performance\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False\nelse:\n    print(\"No GPU available, using CPU instead\")\n\n# Run the attention sweep with 50 trials\nprint(\"Starting attention model sweep (50 trials)...\")\nrun_sweep(attention_sweep_config, count=50)\n\n# Run the vanilla sweep with 50 trials\nprint(\"Starting vanilla model sweep (50 trials)...\")\nrun_sweep(vanilla_sweep_config, count=50)\n\n# Optional: Analysis function for after the sweeps are complete\ndef analyze_sweep_results(sweep_id, project_name=\"transliteration-seq2seq\"):\n    \"\"\"\n    Analyze the results of a sweep and generate visualizations.\n    \"\"\"\n    api = wandb.Api()\n    sweep = api.sweep(f\"{wandb.run.entity}/{project_name}/{sweep_id}\")\n    \n    # Get all runs in the sweep\n    runs = sweep.runs\n    \n    # Extract run data\n    run_data = []\n    for run in runs:\n        if run.state == \"finished\" and run.summary.get(\"test_accuracy\") is not None:\n            run_data.append({\n                \"run_id\": run.id,\n                \"name\": run.name,\n                \"test_accuracy\": run.summary.get(\"test_accuracy\", 0),\n                \"valid_accuracy\": run.summary.get(\"valid_accuracy\", 0),\n                \"config\": {k: v for k, v in run.config.items() if not k.startswith('_')}\n            })\n    \n    # Convert to DataFrame\n    df = pd.DataFrame(run_data)\n    \n    if len(df) == 0:\n        print(\"No completed runs found in the sweep.\")\n        return\n    \n    # Sort by test accuracy\n    df = df.sort_values(\"test_accuracy\", ascending=False)\n    \n    # Print the best run\n    best_run = df.iloc[0]\n    print(f\"Best run: {best_run['name']} (ID: {best_run['run_id']})\")\n    print(f\"Test accuracy: {best_run['test_accuracy']:.4f}\")\n    print(\"Configuration:\")\n    for k, v in best_run['config'].items():\n        print(f\"  {k}: {v}\")\n    \n    # Create a plot of test accuracy vs. hyperparameters\n    plt.figure(figsize=(15, 10))\n    \n    # Select numerical hyperparameters\n    numerical_params = ['embedding_size', 'hidden_size', 'num_layers', 'learning_rate', 'batch_size', 'dropout']\n    \n    for i, param in enumerate(numerical_params):\n        if param in df.columns:\n            plt.subplot(2, 3, i+1)\n            sns.scatterplot(x=param, y='test_accuracy', data=df)\n            plt.title(f'Test Accuracy vs {param}')\n            plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('hyperparameter_analysis.png')\n    plt.show()\n    \n    return df\n\n# Example usage (uncomment to run after sweeps are complete):\n# vanilla_results = analyze_sweep_results(\"YOUR_VANILLA_SWEEP_ID\")\n# attention_results = analyze_sweep_results(\"YOUR_ATTENTION_SWEEP_ID\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:58:01.446199Z","iopub.execute_input":"2025-05-20T16:58:01.446953Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nCUDA device: Tesla T4\nCUDA device count: 2\nStarting attention model sweep (50 trials)...\nCreating sweep with configuration: bayes\nCreate sweep with ID: 8zoszb8i\nSweep URL: https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i\nStarting sweep with ID: 8zoszb8i\nRunning 50 trials.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 32i27dqx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_dir: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007358989864160939\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \trmsprop_alpha: 0.99\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_factor: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_t_max: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_165808-32i27dqx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/32i27dqx' target=\"_blank\">gallant-sweep-1</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/32i27dqx' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/32i27dqx</a>"},"metadata":{}},{"name":"stdout","text":"Actual wandb run name: gallant-sweep-1\nStarting training run with config: {'batch_size': 128, 'cell_type': 'lstm', 'clip': 1, 'data_dir': '/kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0', 'dropout': 0.3, 'embedding_size': 64, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.007358989864160939, 'max_seq_len': 50, 'momentum': 0.9, 'n_epochs': 10, 'num_layers': 2, 'optimizer': 'adam', 'rmsprop_alpha': 0.99, 'scheduler': 'plateau', 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'scheduler_t_max': 10, 'teacher_forcing_ratio': 0.5, 'use_attention': True, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 2,139,826 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047091e32c21462a9bc9a14d454c841b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60c879c2376b423988d835e47d1fd051"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8795c94af1544f75a4401f296fd7c160"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 1m 29s\n\tTrain Loss: 0.2783\n\t Val. Loss: 0.1304\n\t Val. Accuracy: 0.4599\n\t Learning Rate: 0.007359\nSaved new best model to best-model-32i27dqx.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6af71dc2ab4f30a1de55b711f75d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d919f7cf4a64df18cd0627a2ffbead6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffeff593331e49859b766ab5b4ff60dd"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 1m 29s\n\tTrain Loss: 0.0890\n\t Val. Loss: 0.1125\n\t Val. Accuracy: 0.5155\n\t Learning Rate: 0.007359\nSaved new best model to best-model-32i27dqx.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0da6980e8ff42408d30ad09e3247b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf910654e998427c9450f58d067971dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92a6e20a1d146cd9b70b18dfbb96151"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 1m 29s\n\tTrain Loss: 0.0759\n\t Val. Loss: 0.1063\n\t Val. Accuracy: 0.5483\n\t Learning Rate: 0.007359\nSaved new best model to best-model-32i27dqx.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef3f3223a22c493c9677d7e34e48255d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"815daf9b8e94471bb4e9b3e55c2bcd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94661ff210bb4889bbcd224cb9608c84"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 1m 30s\n\tTrain Loss: 0.0680\n\t Val. Loss: 0.1069\n\t Val. Accuracy: 0.5541\n\t Learning Rate: 0.007359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9780b0a4e71d4877be9ef851b811e35c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df82a4a824ff4f0bafa019ab194ee279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3985206ccd45daad1a2ca5f4213236"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 1m 29s\n\tTrain Loss: 0.0639\n\t Val. Loss: 0.1054\n\t Val. Accuracy: 0.5698\n\t Learning Rate: 0.007359\nSaved new best model to best-model-32i27dqx.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d86fff0e700745368df02e75328852fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039c474cb46e404d90e0777f3975f636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996b759dade945acb1d0eed3c1d46168"}},"metadata":{}},{"name":"stdout","text":"Epoch: 06 | Time: 1m 30s\n\tTrain Loss: 0.0611\n\t Val. Loss: 0.1066\n\t Val. Accuracy: 0.5740\n\t Learning Rate: 0.007359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e57e206ffd46498a5627fe982e661d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc0d7a8ea8ec4c10896914567d8e2302"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f585820b27e4455888b27412c7bfa1f4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 07 | Time: 1m 30s\n\tTrain Loss: 0.0585\n\t Val. Loss: 0.1107\n\t Val. Accuracy: 0.5814\n\t Learning Rate: 0.007359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09b7e1dbe244e4a92a59c8c83c90b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2990602db614c92bc04a56e32af8e23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3977602f9f0945a0b28826ce9000625c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 08 | Time: 1m 30s\n\tTrain Loss: 0.0557\n\t Val. Loss: 0.1103\n\t Val. Accuracy: 0.5757\n\t Learning Rate: 0.007359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6ba832d8aa4a55a5f4ade8a4ea1db1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110d6e292d964d24b1e056562dd09b22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec2a7a1b0f8421d91fe9910fb070581"}},"metadata":{}},{"name":"stdout","text":"Epoch: 09 | Time: 1m 30s\n\tTrain Loss: 0.0554\n\t Val. Loss: 0.1067\n\t Val. Accuracy: 0.5893\n\t Learning Rate: 0.007359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343be6dbb3d94db584d79d95f125de78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d325c5f388c44e2902512d87863949d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f50abee15394fd48233a25a763290eb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | Time: 1m 29s\n\tTrain Loss: 0.0523\n\t Val. Loss: 0.1105\n\t Val. Accuracy: 0.5925\n\t Learning Rate: 0.007359\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22de7b1d80da4cc69f9cfa7484e2e791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2c1ea5092645d2bfe43fe7199a308c"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.1132\nTest Accuracy: 0.5533\nSaved predictions to predictions/attention/predictions-32i27dqx.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁█▁████▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▄▆▆▇▇▇▇██</td></tr><tr><td>valid_loss</td><td>█▃▁▁▁▁▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>epoch_time_min</td><td>1</td></tr><tr><td>epoch_time_sec</td><td>29</td></tr><tr><td>learning_rate</td><td>0.00736</td></tr><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>test_accuracy</td><td>0.55332</td></tr><tr><td>test_loss</td><td>0.11317</td></tr><tr><td>train_loss</td><td>0.05228</td></tr><tr><td>trainable_parameters</td><td>2139826</td></tr><tr><td>valid_accuracy</td><td>0.5925</td></tr><tr><td>valid_loss</td><td>0.11053</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gallant-sweep-1</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/32i27dqx' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/32i27dqx</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_165808-32i27dqx/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: emvjocj7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_dir: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008867107959822679\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \trmsprop_alpha: 0.99\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_factor: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_t_max: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_171340-emvjocj7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/emvjocj7' target=\"_blank\">elated-sweep-2</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/emvjocj7' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/emvjocj7</a>"},"metadata":{}},{"name":"stdout","text":"Actual wandb run name: elated-sweep-2\nStarting training run with config: {'batch_size': 128, 'cell_type': 'lstm', 'clip': 1, 'data_dir': '/kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0', 'dropout': 0, 'embedding_size': 32, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.008867107959822679, 'max_seq_len': 50, 'momentum': 0, 'n_epochs': 10, 'num_layers': 1, 'optimizer': 'rmsprop', 'rmsprop_alpha': 0.99, 'scheduler': 'none', 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'scheduler_t_max': 10, 'teacher_forcing_ratio': 0.5, 'use_attention': True, 'weight_decay': 0.001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 85,490 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca836b1969a4f77af66ed35ab984216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9350d0bd49435a9d4f5381921f68c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6957829c2c324502a400c87d4f4b8697"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 1m 7s\n\tTrain Loss: 0.5448\n\t Val. Loss: 0.5426\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\nSaved new best model to best-model-emvjocj7.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce72b78d63740928f91ba86333dff4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6918c0658bfb4a3299bb058c47b835d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e77e7619e0554b6ca39f994105e0594d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 1m 6s\n\tTrain Loss: 0.5394\n\t Val. Loss: 0.5511\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c24ba512a04e4c1e9a757dd9e806109b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcdad63c0ca44cb58358344a96cb0691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2b437617864a8c9ce1659cdfcab7fb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 1m 7s\n\tTrain Loss: 0.5390\n\t Val. Loss: 0.5426\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec9528f9d5e4d9292f70d893bd7b656"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f9c2f7e721b465cb50a810f2a9c9d82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f254d3e1244b73a1618b69043cf3ce"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 1m 8s\n\tTrain Loss: 0.5377\n\t Val. Loss: 0.5446\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16912e661f94bf89f6f7f1bfe1faf19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a4120280554d92a4247892332c2bc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52c47fa43b7040248306d526f0ec6278"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 1m 8s\n\tTrain Loss: 0.5376\n\t Val. Loss: 0.5449\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca9e5d5d0b1487e919cae6a6ee4c540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"483aa580541a41d1b8f5b58edde0e430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f685be5a4ac4dda9c6c16dfbb4517c9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 06 | Time: 1m 8s\n\tTrain Loss: 0.5374\n\t Val. Loss: 0.5409\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\nSaved new best model to best-model-emvjocj7.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f292a732f04e3ba6fbaf5cd3d572b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3388479fd66d4bb9b65bb1cf8c14dd6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2f8ae86eea43e3a9406be79d2abaf7"}},"metadata":{}},{"name":"stdout","text":"Epoch: 07 | Time: 1m 7s\n\tTrain Loss: 0.5350\n\t Val. Loss: 0.5467\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba86e4f6afff463cb8d390d7e4ffe714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d02ce14f600c4bd19fa5c2f079dfd6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9788935b68784e4fb895405f7d140024"}},"metadata":{}},{"name":"stdout","text":"Epoch: 08 | Time: 1m 7s\n\tTrain Loss: 0.5368\n\t Val. Loss: 0.5396\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\nSaved new best model to best-model-emvjocj7.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e464fbca5cc47ef99d7d93b85b0ccd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffcf6e14416c497a91a93add7da64458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80138d7b9745459290a2caa977e58412"}},"metadata":{}},{"name":"stdout","text":"Epoch: 09 | Time: 1m 8s\n\tTrain Loss: 0.5352\n\t Val. Loss: 0.5432\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c853fbcc459f4a64bc7a38484b483aa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22cff851b2834fd0acf6ec46e24ce9da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6712cbf2cdfd49a3b0e9a58acd96c460"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | Time: 1m 8s\n\tTrain Loss: 0.5362\n\t Val. Loss: 0.5442\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.008867\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5986319963f440daa47622d5fd3a600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"444685cab9004eeca8123cdee50e9e92"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5450\nTest Accuracy: 0.0000\nSaved predictions to predictions/attention/predictions-emvjocj7.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▅▁▅███▅▅██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▃▁▂▁▂</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▃█▃▄▄▂▅▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>epoch_time_min</td><td>1</td></tr><tr><td>epoch_time_sec</td><td>8</td></tr><tr><td>learning_rate</td><td>0.00887</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.54495</td></tr><tr><td>train_loss</td><td>0.53617</td></tr><tr><td>trainable_parameters</td><td>85490</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.54418</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">elated-sweep-2</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/emvjocj7' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/emvjocj7</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_171340-emvjocj7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: up75067f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_dir: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004061607321958502\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \trmsprop_alpha: 0.99\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_factor: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_t_max: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_172520-up75067f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/up75067f' target=\"_blank\">polar-sweep-3</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/8zoszb8i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/up75067f' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/up75067f</a>"},"metadata":{}},{"name":"stdout","text":"Actual wandb run name: polar-sweep-3\nStarting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'data_dir': '/kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0', 'dropout': 0, 'embedding_size': 64, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.004061607321958502, 'max_seq_len': 50, 'momentum': 0, 'n_epochs': 10, 'num_layers': 2, 'optimizer': 'adam', 'rmsprop_alpha': 0.99, 'scheduler': 'none', 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'scheduler_t_max': 10, 'teacher_forcing_ratio': 0.7, 'use_attention': True, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 1,646,258 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b631d265ec4126b961f4440451fcc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf429750866c445ca15a489d0581bc01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca585dc495d943ff94baa7a2a294a8dc"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 4m 58s\n\tTrain Loss: 0.2283\n\t Val. Loss: 0.1519\n\t Val. Accuracy: 0.3895\n\t Learning Rate: 0.004062\nSaved new best model to best-model-up75067f.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dedaa263a94240abbcba7380d9f5c9dd"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"def run_sweep(sweep_config, count=50):\n    \"\"\"\n    Runs a wandb hyperparameter sweep with a descriptive name based on key hyperparameters.\n    \"\"\"\n    # Generate a descriptive name for the sweep\n    params = sweep_config['parameters']\n    \n    # Get fixed parameters for the name\n    model_type = \"attention\" if params['use_attention']['value'] else \"vanilla\"\n    language = params['language']['value']\n    \n    # Get ranges for variable parameters\n    embedding_sizes = params.get('embedding_size', {}).get('values', ['default'])\n    if not isinstance(embedding_sizes, list):\n        embedding_sizes = [embedding_sizes]\n    embedding_range = f\"emb{min(embedding_sizes)}-{max(embedding_sizes)}\" if len(embedding_sizes) > 1 else f\"emb{embedding_sizes[0]}\"\n    \n    hidden_sizes = params.get('hidden_size', {}).get('values', ['default'])\n    if not isinstance(hidden_sizes, list):\n        hidden_sizes = [hidden_sizes]\n    hidden_range = f\"hid{min(hidden_sizes)}-{max(hidden_sizes)}\" if len(hidden_sizes) > 1 else f\"hid{hidden_sizes[0]}\"\n    \n    # Get layer information\n    if 'num_layers' in params:\n        layers = params['num_layers'].get('values', [1])\n        if not isinstance(layers, list):\n            layers = [layers]\n        layers_range = f\"layers{min(layers)}-{max(layers)}\" if len(layers) > 1 else f\"layers{layers[0]}\"\n    else:\n        enc_layers = params.get('encoder_layers', {}).get('values', [1])\n        dec_layers = params.get('decoder_layers', {}).get('values', [1])\n        if not isinstance(enc_layers, list):\n            enc_layers = [enc_layers]\n        if not isinstance(dec_layers, list):\n            dec_layers = [dec_layers]\n        layers_range = f\"enc{min(enc_layers)}-{max(enc_layers)}_dec{min(dec_layers)}-{max(dec_layers)}\"\n    \n    # Get cell type\n    cell_types = params.get('cell_type', {}).get('values', ['lstm'])\n    if not isinstance(cell_types, list):\n        cell_types = [cell_types]\n    cell_type_str = \"-\".join(cell_types)\n    \n    # Get optimizer info\n    optimizers = params.get('optimizer', {}).get('values', ['adam'])\n    if not isinstance(optimizers, list):\n        optimizers = [optimizers]\n    optimizer_str = \"-\".join(optimizers)\n    \n    # Get learning rate range\n    if 'learning_rate' in params:\n        if 'distribution' in params['learning_rate']:\n            lr_min = params['learning_rate'].get('min', 0.0001)\n            lr_max = params['learning_rate'].get('max', 0.01)\n            lr_range = f\"lr{lr_min}-{lr_max}\"\n        elif 'values' in params['learning_rate']:\n            lr_values = params['learning_rate']['values']\n            lr_range = f\"lr{min(lr_values)}-{max(lr_values)}\" if len(lr_values) > 1 else f\"lr{lr_values[0]}\"\n        else:\n            lr_range = f\"lr{params['learning_rate'].get('value', 'default')}\"\n    else:\n        lr_range = \"lr-default\"\n    \n    # Get dropout range\n    dropouts = params.get('dropout', {}).get('values', [0.0])\n    if not isinstance(dropouts, list):\n        dropouts = [dropouts]\n    dropout_range = f\"drop{min(dropouts)}-{max(dropouts)}\" if len(dropouts) > 1 else f\"drop{dropouts[0]}\"\n    \n    # Add timestamp for uniqueness\n    import datetime\n    timestamp = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n    \n    # Combine all parts into a descriptive name\n    sweep_name = f\"{language}_{model_type}_{cell_type_str}_{embedding_range}_{hidden_range}_{layers_range}_{dropout_range}_{optimizer_str}_{lr_range}_{timestamp}\"\n\n    sweep_config['name'] = sweep_name\n    \n    print(f\"Creating sweep with name: {sweep_name}\")\n    sweep_id = wandb.sweep(\n        sweep_config, \n        project=\"transliteration-seq2seq\",\n    )\n    print(f\"Starting sweep with ID: {sweep_id}\")\n    print(f\"Running {count} trials.\")\n    wandb.agent(sweep_id, train_model, count=count)\n\n# Define sweep configuration for vanilla model (no attention)\nvanilla_sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'valid_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'language': {'value': 'ta'},\n        'embedding_size': {'values': [128, 32, 64]},\n        'hidden_size': {'values': [256, 64, 128]},\n        'encoder_layers': {'values': [1, 2, 3]},\n        'decoder_layers': {'values': [1, 2, 3]},\n        'cell_type': {'values': ['lstm', 'gru']},\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n        'optimizer': {'values': ['adam', 'rmsprop']},\n        'learning_rate': {'distribution': 'log_uniform_values', 'min': 0.0001, 'max': 0.01},\n        'weight_decay': {'values': [0, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'n_epochs': {'value': 5},  # 5 epochs per run as requested\n        'clip': {'value': 1.0},\n        'teacher_forcing_ratio': {'values': [0.5, 0.7]},\n        'use_attention': {'value': False},\n        'max_seq_len': {'value': 50},\n        'scheduler': {'values': ['none', 'plateau']}\n    }\n}\n\n# Define sweep configuration for attention model\nattention_sweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'valid_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'language': {'value': 'ta'},\n        'embedding_size': {'values': [128, 64, 32]},\n        'hidden_size': {'values': [256, 128, 64]},\n        'encoder_layers': {'values': [1, 2, 3, 4, 5]},\n        'decoder_layers': {'values': [1, 2, 3, 4, 5]},\n        'cell_type': {'values': ['lstm', 'gru']},\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n        'optimizer': {'values': ['adam', 'rmsprop']},\n        'learning_rate': {'distribution': 'log_uniform_values', 'min': 0.0001, 'max': 0.01},\n        'weight_decay': {'values': [0, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'n_epochs': {'value': 5},  # 5 epochs per run as requested\n        'clip': {'value': 1.0},\n        'teacher_forcing_ratio': {'values': [0.5, 0.7]},\n        'use_attention': {'value': True},\n        'max_seq_len': {'value': 50},\n        'scheduler': {'values': ['none', 'plateau']}\n    }\n}\n\n# Run the vanilla sweep with 50 trials\nprint(\"Starting vanilla model sweep (50 trials)...\")\nrun_sweep(vanilla_sweep_config, count=50)\n\n# Run the attention sweep with 50 trials\nprint(\"Starting attention model sweep (50 trials)...\")\nrun_sweep(attention_sweep_config, count=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T12:25:38.681403Z","iopub.execute_input":"2025-05-20T12:25:38.682141Z","execution_failed":"2025-05-20T15:33:00.908Z"}},"outputs":[{"name":"stdout","text":"Starting vanilla model sweep (50 trials)...\nCreating sweep with name: ta_vanilla_lstm-gru_emb32-128_hid64-256_enc1-3_dec1-3_drop0.0-0.3_adam-rmsprop_lr0.0001-0.01_0520-1225\nCreate sweep with ID: mbrh064k\nSweep URL: https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k\nStarting sweep with ID: mbrh064k\nRunning 50 trials.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run raz3p6ob errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3412yiok with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004152277870643743\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_122600-3412yiok</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/3412yiok' target=\"_blank\">astral-sweep-2</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/3412yiok' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/3412yiok</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 64, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 2, 'dropout': 0, 'embedding_size': 128, 'encoder_layers': 2, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0004152277870643743, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 179,378 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7930a06697854e85a3672cf46125665d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8289c4dbb0ab481abd1a3c3168447ce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9c4fa09a794347a3c053251e47674b"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 1m 25s\n\tTrain Loss: 0.5831\n\t Val. Loss: 0.5251\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000415\nSaved new best model to best-model-3412yiok.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e1ef52b58d486aac2326c0ed05c345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a77d646f2eb470cb6518ce8234926ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8bd815d47784420a0accb48de2c144a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 1m 25s\n\tTrain Loss: 0.5365\n\t Val. Loss: 0.5080\n\t Val. Accuracy: 0.0004\n\t Learning Rate: 0.000415\nSaved new best model to best-model-3412yiok.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e26a86650f4ed088cb81b7f906de73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ae6248104a47e3bf997652173d3107"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804961530c86423ba83a198999fd4188"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 1m 25s\n\tTrain Loss: 0.4777\n\t Val. Loss: 0.5338\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000415\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b648a2eda97a40c98132be5ad1b53f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"babf1141d6c747b8a97c580a5994b8b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291f1a28a8e5419ba1818b86abff7e3a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 1m 26s\n\tTrain Loss: 0.4620\n\t Val. Loss: 0.5308\n\t Val. Accuracy: 0.0004\n\t Learning Rate: 0.000415\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a348e3c65ef4cfc964268c1f5d9772b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a077775b064a578abaa479285be599"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ddce24a13134b8c9bca217b000952e4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 1m 26s\n\tTrain Loss: 0.4520\n\t Val. Loss: 0.5284\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000415\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1e0de881964626b3e6657d7b69206a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5932536fda1f46418e430d1247544e75"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5122 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-3412yiok.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▂▂▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁█▁█▁</td></tr><tr><td>valid_loss</td><td>▆▁█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>1</td></tr><tr><td>epoch_time_sec</td><td>26</td></tr><tr><td>learning_rate</td><td>0.00042</td></tr><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.51221</td></tr><tr><td>train_loss</td><td>0.45195</td></tr><tr><td>trainable_parameters</td><td>179378</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.52838</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">astral-sweep-2</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/3412yiok' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/3412yiok</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_122600-3412yiok/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1mez5v7t errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kkc9m416 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007808362384340169\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_123336-kkc9m416</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/kkc9m416' target=\"_blank\">fragrant-sweep-4</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/kkc9m416' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/kkc9m416</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.3, 'embedding_size': 128, 'encoder_layers': 1, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.0007808362384340169, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 1,010,738 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07819d1755c14927a03c3c979d732883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51cf2985ba364bbfb1bfbc87c20cc293"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f694553f10043e9bc628d630219742d"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (2, 32, 256), got [1, 32, 256]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>1010738</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fragrant-sweep-4</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/kkc9m416' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/kkc9m416</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_123336-kkc9m416/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run kkc9m416 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (2, 32, 256), got [1, 32, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run v93g18vv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: flumypgm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005862946897153711\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_123654-flumypgm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/flumypgm' target=\"_blank\">comfy-sweep-6</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/flumypgm' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/flumypgm</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 3, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.0005862946897153711, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 1,302,066 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb473bacf0940e298a2cc1e009af9f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00536ee5a5944a7fa9ef65223d8e8890"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea9f2a2c3f240069142458fa9b0ae32"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (3, 32, 256), got [1, 32, 256]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>1302066</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">comfy-sweep-6</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/flumypgm' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/flumypgm</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_123654-flumypgm/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run flumypgm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (3, 32, 256), got [1, 32, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run osab03x5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0lj3je3y with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006663942370879322\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_124043-0lj3je3y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/0lj3je3y' target=\"_blank\">floral-sweep-8</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/0lj3je3y' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/0lj3je3y</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0, 'embedding_size': 32, 'encoder_layers': 2, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0006663942370879322, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 93,362 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e84b612fb54b4cce923deeecb9fbe902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2995c1ebb674b1288c28ad0460159ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7b0c88dbe84f6e98be0382874dbbf0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 2m 34s\n\tTrain Loss: 0.5412\n\t Val. Loss: 0.5356\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000666\nSaved new best model to best-model-0lj3je3y.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64998f0f550b4b979eb3465f24c239ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561ad89a31794907b8fc2af45eb22642"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e88c294d8154bffbd221457167a394e"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 2m 35s\n\tTrain Loss: 0.5059\n\t Val. Loss: 0.5397\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd170702620642e491a73415c345fb75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f4e4ffe03d4eb7b90aa7ab582e17ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134fc537138e4a638b0c1284653db549"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 2m 35s\n\tTrain Loss: 0.4966\n\t Val. Loss: 0.5381\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54a20edb99b4e29b47db8f849c0033f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bbafb62dcd4c42a30267f80a8e070b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b20632719eb43df84c3d0ec577b7acd"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 2m 35s\n\tTrain Loss: 0.4910\n\t Val. Loss: 0.5500\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cded34a2d8e7420d8fee4b2f54b8f3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff11ab470b44c3299e35cd3c17638f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12590c85868442a3a185fd0b6d83050e"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 2m 35s\n\tTrain Loss: 0.4869\n\t Val. Loss: 0.5349\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000666\nSaved new best model to best-model-0lj3je3y.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010eddd26d2843aa8cd96dc66312f02e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ec5ef812b454180b2f056f0fdd3c710"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5393 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-0lj3je3y.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▁▃▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>2</td></tr><tr><td>epoch_time_sec</td><td>35</td></tr><tr><td>learning_rate</td><td>0.00067</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.53926</td></tr><tr><td>train_loss</td><td>0.48685</td></tr><tr><td>trainable_parameters</td><td>93362</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.53491</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">floral-sweep-8</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/0lj3je3y' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/0lj3je3y</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_124043-0lj3je3y/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ga3uw70h errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f0mu5ft1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002014522681314444\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_125409-f0mu5ft1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/f0mu5ft1' target=\"_blank\">toasty-sweep-10</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/f0mu5ft1' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/f0mu5ft1</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 3, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.0002014522681314444, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 474,418 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd27fb6e1d1426394715be3c5a28c47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719938fb44454d6c914cb2906266b086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f9801bbd3c40d182ee9c8b38826bcc"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n    decoder_output, hidden, cell = model.decoder(\n                                   ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n    self.check_hidden_size(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden[0] size (3, 32, 128), got [1, 32, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>474418</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">toasty-sweep-10</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/f0mu5ft1' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/f0mu5ft1</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_125409-f0mu5ft1/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run f0mu5ft1 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, cell = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden[0] size (3, 32, 128), got [1, 32, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nbx3anqz errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k5cvs6mq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015736418604743196\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_125802-k5cvs6mq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/k5cvs6mq' target=\"_blank\">deep-sweep-12</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/k5cvs6mq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/k5cvs6mq</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 3, 'dropout': 0, 'embedding_size': 128, 'encoder_layers': 3, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0015736418604743196, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 187,826 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee6ff8b540546e69ed91fbffeef0e8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8405f329301470fb423f7e5d3c6aeb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf36d0f68014a6483254546badc68b9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 3m 5s\n\tTrain Loss: 0.5567\n\t Val. Loss: 0.5242\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001574\nSaved new best model to best-model-k5cvs6mq.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba5336cbc36468b94527b70df4bdc27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ddaece324014095bc393d163d6f70bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd10c45133224cd1ab539a48869c166c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 3m 5s\n\tTrain Loss: 0.5026\n\t Val. Loss: 0.5634\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001574\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d85517c02a5d48189e8baada4ae006ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b16991bb39948c99fe2ff26e662db10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16bd92e8f17f433cb37e5328dc1490f6"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 3m 4s\n\tTrain Loss: 0.4414\n\t Val. Loss: 0.5743\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001574\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb6a0d105c143bcbf0dcc58cae7166b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa2fce420da4dbaa91a9709fdd91ab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7f2b8eec7048ea9f560bf12d9d6d29"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 3m 5s\n\tTrain Loss: 0.4336\n\t Val. Loss: 0.5665\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001574\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5038207a6ae4e5c8e428cf42a753d70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d9ec2fb7eb498db9a0abfd2887d17c"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5294 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-k5cvs6mq.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>██▁▁█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▂▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▁▆▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>3</td></tr><tr><td>epoch_time_sec</td><td>5</td></tr><tr><td>learning_rate</td><td>0.00157</td></tr><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.52941</td></tr><tr><td>train_loss</td><td>0.43362</td></tr><tr><td>trainable_parameters</td><td>187826</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.56649</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">deep-sweep-12</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/k5cvs6mq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/k5cvs6mq</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_125802-k5cvs6mq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ka5lylte errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1tfdoku0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002307102971116781\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_131401-1tfdoku0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/1tfdoku0' target=\"_blank\">earthy-sweep-14</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/1tfdoku0' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/1tfdoku0</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 1, 'dropout': 0, 'embedding_size': 32, 'encoder_layers': 2, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0002307102971116781, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 89,266 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29d2f54dac14263abc13a0a33f658f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d91f6b539d8437684c8fb90e2fd6f06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dd609288a264d02877358fbc125d44d"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n    decoder_output, hidden, cell = model.decoder(\n                                   ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n    self.check_hidden_size(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden[0] size (1, 128, 64), got [2, 128, 64]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>89266</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earthy-sweep-14</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/1tfdoku0' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/1tfdoku0</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_131401-1tfdoku0/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1tfdoku0 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, cell = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden[0] size (1, 128, 64), got [2, 128, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run i9c0nfkt errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: amh9b2uz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00023353827737786917\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_131503-amh9b2uz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/amh9b2uz' target=\"_blank\">worthy-sweep-16</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/amh9b2uz' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/amh9b2uz</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 64, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 3, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 3, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.00023353827737786917, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 2,782,770 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610f2283933746e69a22d6edaf20817b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d43548ea8f446a1885d49b437aea397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cf9411b8a34e2ebac08574ef71f93b"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 2m 5s\n\tTrain Loss: 0.5614\n\t Val. Loss: 0.5239\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000234\nSaved new best model to best-model-amh9b2uz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985ee5d6c4ae469bbdbb0974b3dd22df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdacee87390c4ac6b2b281593e4950e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945c51547d2a434c86a7bc0a538cb27d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 2m 5s\n\tTrain Loss: 0.5535\n\t Val. Loss: 0.5224\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000234\nSaved new best model to best-model-amh9b2uz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db1a62a9af045b789483c3a18aafb66"}},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=10000.0 (msgs/sec)\nNotebookApp.rate_limit_window=1.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e92739965aaa41b5b55f504995c86145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae04ffe132d45d295f5fcdf4e541390"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 0m 37s\n\tTrain Loss: 0.2637\n\t Val. Loss: 0.3112\n\t Val. Accuracy: 0.0845\n\t Learning Rate: 0.006821\nSaved new best model to best-model-raz3p6ob.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de93ebea62c400cbcbeaad8c1f5e19e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb57cee20584385b740e4494dede141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e76666b73ff54edf9d8dba88552f2e1f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 0m 37s\n\tTrain Loss: 0.2252\n\t Val. Loss: 0.2775\n\t Val. Accuracy: 0.1412\n\t Learning Rate: 0.006821\nSaved new best model to best-model-raz3p6ob.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4225a82f14534d048b96bcdb68225df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f034594fb2864ac1baf886613ceb0c28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3685682d16174761b9a4c114a3ce9def"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 0m 37s\n\tTrain Loss: 0.2061\n\t Val. Loss: 0.2645\n\t Val. Accuracy: 0.1695\n\t Learning Rate: 0.006821\nSaved new best model to best-model-raz3p6ob.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde7efc2753e49bfbbe3f405a7fddd38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6b98be719fc4cafb5ffdb15b158781e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee0de8897ab044aca6c28362359d8b88"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 0m 37s\n\tTrain Loss: 0.1918\n\t Val. Loss: 0.2481\n\t Val. Accuracy: 0.1790\n\t Learning Rate: 0.006821\nSaved new best model to best-model-raz3p6ob.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"646cc748f3ee4a74a117685c141208db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d13f0586d53d4392997a9167c9b268c2"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.2522 | Test Accuracy: 0.1734\nSaved predictions to predictions/vanilla/predictions-raz3p6ob.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▂▂▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▃▆██</td></tr><tr><td>valid_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>0</td></tr><tr><td>epoch_time_sec</td><td>37</td></tr><tr><td>learning_rate</td><td>0.00682</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0.17337</td></tr><tr><td>test_loss</td><td>0.25218</td></tr><tr><td>train_loss</td><td>0.19181</td></tr><tr><td>trainable_parameters</td><td>58290</td></tr><tr><td>valid_accuracy</td><td>0.179</td></tr><tr><td>valid_loss</td><td>0.24814</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dulcet-sweep-1</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/raz3p6ob' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/raz3p6ob</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_132557-raz3p6ob/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run y34w1kny errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: abn7vhiz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005062030007522182\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_132931-abn7vhiz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/abn7vhiz' target=\"_blank\">grateful-sweep-19</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/abn7vhiz' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/abn7vhiz</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.005062030007522182, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 160,562 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb177179828440d3a9151c35bf9eb3c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e15f4b10cf442f39c8c732bb8161788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed3b85aea95c444e97ef0cd8140a6d5a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 0m 37s\n\tTrain Loss: 0.4826\n\t Val. Loss: 0.4636\n\t Val. Accuracy: 0.0012\n\t Learning Rate: 0.005062\nSaved new best model to best-model-abn7vhiz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a247d53712364042b4cd436f062d6e7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eac3b67b4314d4489952dcd408c7d62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cce7eb89087a4c41be3628dfaa4a6fcc"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 0m 37s\n\tTrain Loss: 0.2881\n\t Val. Loss: 0.2964\n\t Val. Accuracy: 0.1182\n\t Learning Rate: 0.005062\nSaved new best model to best-model-abn7vhiz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf72b4a62e04b5baa36d77e0c9aedb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29520049e5a144a7a7a2e8d3ee772411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e60cb7b36d694075aaa35d09c22f65ae"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 0m 37s\n\tTrain Loss: 0.1904\n\t Val. Loss: 0.2476\n\t Val. Accuracy: 0.2161\n\t Learning Rate: 0.005062\nSaved new best model to best-model-abn7vhiz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457c1a8af4134d28a5a1c32eb6ae05d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe722a7d90a2478eac7c544a10981e18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf89a143808b45b48c99e9696a01c5b7"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 0m 37s\n\tTrain Loss: 0.1569\n\t Val. Loss: 0.2137\n\t Val. Accuracy: 0.2695\n\t Learning Rate: 0.005062\nSaved new best model to best-model-abn7vhiz.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226fed40b0db46b98dca5ea02fa36647"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c85878a3844811b1813e2a037a7354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3c2e1a7860442489fac4771e4ccd7bf"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 0m 37s\n\tTrain Loss: 0.1381\n\t Val. Loss: 0.2023\n\t Val. Accuracy: 0.3123\n\t Learning Rate: 0.005062\nSaved new best model to best-model-abn7vhiz.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0553ce6a6ca749b6b82c4b2ac2c6119b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc1f61b5d7bb4237831ffbd8759ff2b5"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.2133 | Test Accuracy: 0.2972\nSaved predictions to predictions/vanilla/predictions-abn7vhiz.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▂▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>valid_loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>0</td></tr><tr><td>epoch_time_sec</td><td>37</td></tr><tr><td>learning_rate</td><td>0.00506</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0.2972</td></tr><tr><td>test_loss</td><td>0.21333</td></tr><tr><td>train_loss</td><td>0.13807</td></tr><tr><td>trainable_parameters</td><td>160562</td></tr><tr><td>valid_accuracy</td><td>0.31229</td></tr><tr><td>valid_loss</td><td>0.20231</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-sweep-19</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/abn7vhiz' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/abn7vhiz</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_132931-abn7vhiz/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 55l08upl errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8tq0ezne with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004231397083875456\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_133305-8tq0ezne</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/8tq0ezne' target=\"_blank\">autumn-sweep-21</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/8tq0ezne' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/8tq0ezne</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.3, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.0004231397083875456, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 259,634 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49c383a9f1cf4234ba32be4d58306588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85cf45efbd374f9aaa1059165e508894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302463a20fdf47f4a2b2b5fe9539eb52"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (2, 128, 128), got [1, 128, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>259634</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">autumn-sweep-21</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/8tq0ezne' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/8tq0ezne</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_133305-8tq0ezne/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8tq0ezne errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (2, 128, 128), got [1, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1mez5v7t errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r7ehwoiq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004604635216373744\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_133416-r7ehwoiq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/r7ehwoiq' target=\"_blank\">electric-sweep-22</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/r7ehwoiq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/r7ehwoiq</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 2, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.004604635216373744, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 259,634 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d13a13e0a3c940e386aa8492b7b1029f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc383bd222354b1ca19d051670b0babe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ef570dae8044378bcb9b567895141c"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (1, 128, 128), got [2, 128, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>trainable_parameters</td><td>259634</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">electric-sweep-22</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/r7ehwoiq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/r7ehwoiq</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_133416-r7ehwoiq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run r7ehwoiq errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (1, 128, 128), got [2, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run imbztecv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o9zdmb54 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0036617430705565023\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_133517-o9zdmb54</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/o9zdmb54' target=\"_blank\">light-sweep-24</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/o9zdmb54' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/o9zdmb54</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 64, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.3, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0036617430705565023, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 83,250 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb7c3a0986b4e9ca591e525fa56df7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6b274c94824c6295df6ce95d583380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c00398cf2f0a4393951c13e41dc39882"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (2, 64, 64), got [1, 64, 64]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>83250</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">light-sweep-24</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/o9zdmb54' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/o9zdmb54</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_133517-o9zdmb54/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run o9zdmb54 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (2, 64, 64), got [1, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run v93g18vv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5d4x400u with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00478407121233276\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_133704-5d4x400u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/5d4x400u' target=\"_blank\">eager-sweep-25</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/5d4x400u' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/5d4x400u</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.00478407121233276, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 58,290 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db30cd4e48f94adda5ac0e3b0450890c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8218410078354ed18d71e176ea99241b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af59f52a93c4edd98ccc7a2db063bf4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 0m 37s\n\tTrain Loss: 0.5145\n\t Val. Loss: 0.5509\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.004784\nSaved new best model to best-model-5d4x400u.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"892ae84d7238437b88a3e9f5922d9307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d097293d6a44d584e9f4573d45a277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc7c70992803470280a7d0ab76acc930"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 0m 36s\n\tTrain Loss: 0.4970\n\t Val. Loss: 0.5435\n\t Val. Accuracy: 0.0004\n\t Learning Rate: 0.004784\nSaved new best model to best-model-5d4x400u.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8188f6c3680640309738cda77cb8b215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41208c5e95004a41b9c3087082f1f434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8856d20874e8487c8dbe7ce42e08deca"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 0m 37s\n\tTrain Loss: 0.4910\n\t Val. Loss: 0.5441\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.004784\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50c139e19b74f82bf2fa7590d74f73c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e44babba8a48458913400842d04c78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986a0ee409e648248281a488e83e8190"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 0m 36s\n\tTrain Loss: 0.4874\n\t Val. Loss: 0.5307\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.004784\nSaved new best model to best-model-5d4x400u.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c88f15f3af24add9b700f2dd22f4ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55396ab3b7ae4edca3096cfa9839d6a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c83e81c616c34ad281125745c7861793"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 0m 37s\n\tTrain Loss: 0.4883\n\t Val. Loss: 0.5435\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.004784\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3832e6f91344f589d69e602305aa38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325f46f5d02b49da9ba388c7e4a35227"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5355 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-5d4x400u.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>█▁█▁█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁█▁▁▁</td></tr><tr><td>valid_loss</td><td>█▅▆▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>0</td></tr><tr><td>epoch_time_sec</td><td>37</td></tr><tr><td>learning_rate</td><td>0.00478</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.53554</td></tr><tr><td>train_loss</td><td>0.48832</td></tr><tr><td>trainable_parameters</td><td>58290</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.54353</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-sweep-25</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/5d4x400u' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/5d4x400u</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_133704-5d4x400u/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 6dfmcbw1 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: osab03x5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00011318208065660135\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_134038-osab03x5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/osab03x5' target=\"_blank\">spring-sweep-7</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/osab03x5' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/osab03x5</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.2, 'embedding_size': 32, 'encoder_layers': 2, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.00011318208065660135, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 1,250,354 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0979c900572d454280364f7cd75a1f10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"702e04c97a1a47259281c84ba46e740e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c277a07fcfb1445eb8fdae51277c43f4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 3m 3s\n\tTrain Loss: 0.5628\n\t Val. Loss: 0.5236\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000113\nSaved new best model to best-model-osab03x5.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04d24b4e9f4d4a20857e92055688eb06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d4c3c8390034cc19a6cad21865442ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d888acecd3a64b1786f7894098da0fb5"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 3m 3s\n\tTrain Loss: 0.5535\n\t Val. Loss: 0.5230\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000113\nSaved new best model to best-model-osab03x5.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"145c6e52026a47deb56074aa19fb7dcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd894cb00969405882e6bf3fbb2b7bbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ca178e494b4e21ac26312584b0e51d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 3m 4s\n\tTrain Loss: 0.5532\n\t Val. Loss: 0.5238\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000113\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc9c7fe03334b7e9681c33933b77a9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6126b703a054f12af165c04a23f0aac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0cf017405384bf09793c81a5b6dd49d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 3m 3s\n\tTrain Loss: 0.5528\n\t Val. Loss: 0.5217\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000113\nSaved new best model to best-model-osab03x5.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d23a025f934b49be94ba08b687d009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31372ca3df314fb2816d66d06e58c79f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3363b3f28f4196b387afbc2fb9aaf2"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 3m 4s\n\tTrain Loss: 0.5528\n\t Val. Loss: 0.5238\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000113\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7101c05d047f4cb7abe11412619e3853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4451ed68124f44a88143a0d5dc08bd79"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5272 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-osab03x5.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁█▁█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▇▅█▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>3</td></tr><tr><td>epoch_time_sec</td><td>4</td></tr><tr><td>learning_rate</td><td>0.00011</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.52718</td></tr><tr><td>train_loss</td><td>0.55277</td></tr><tr><td>trainable_parameters</td><td>1250354</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.52376</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">spring-sweep-7</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/osab03x5' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/osab03x5</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_134038-osab03x5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ga3uw70h errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iqgyxcen with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008857882695058831\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_135631-iqgyxcen</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/iqgyxcen' target=\"_blank\">radiant-sweep-27</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/iqgyxcen' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/iqgyxcen</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 64, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.3, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.008857882695058831, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 58,290 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9693fc5ff4f423a8c292917f6ca8fa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4df2dd1d854ba18979bbd20fb92c0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1595ac9b16984655b922f9cce059691d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 1m 10s\n\tTrain Loss: 0.3830\n\t Val. Loss: 0.3920\n\t Val. Accuracy: 0.0277\n\t Learning Rate: 0.008858\nSaved new best model to best-model-iqgyxcen.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66c870336884fd1b0b67291af42251f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a3fc89df85441c9c918ab43ba5c29e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c886b082c3da4b09b2c75a3c5c81e8b9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 1m 10s\n\tTrain Loss: 0.2474\n\t Val. Loss: 0.3222\n\t Val. Accuracy: 0.1022\n\t Learning Rate: 0.008858\nSaved new best model to best-model-iqgyxcen.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a821f6b3d46e4d2db047d37abbea51bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd453bf377b4af292f479a66708c2a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808de26d44c04949a5a5ad01e8830280"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 1m 10s\n\tTrain Loss: 0.2139\n\t Val. Loss: 0.3025\n\t Val. Accuracy: 0.1274\n\t Learning Rate: 0.008858\nSaved new best model to best-model-iqgyxcen.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b89f97f04c3a4975beccb11bfa02eec6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a6e6b17e5424ec6b7509cf27f8e332b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"952a476eac204af0aa1136ca17b842f4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 1m 10s\n\tTrain Loss: 0.1998\n\t Val. Loss: 0.2890\n\t Val. Accuracy: 0.1561\n\t Learning Rate: 0.008858\nSaved new best model to best-model-iqgyxcen.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aafc5502d7744c2b4feb0002ee0a93e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbd652d748d94bc2bb06b3357f526c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e69e21abe5645e0a42bc8c95dcf2e25"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 1m 10s\n\tTrain Loss: 0.1950\n\t Val. Loss: 0.2818\n\t Val. Accuracy: 0.1501\n\t Learning Rate: 0.008858\nSaved new best model to best-model-iqgyxcen.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ca754d21eb44b1bca6e7697513c7c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cc959d2f5542f89ed04d407af86c32"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.2887 | Test Accuracy: 0.1436\nSaved predictions to predictions/vanilla/predictions-iqgyxcen.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▅▆██</td></tr><tr><td>valid_loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>1</td></tr><tr><td>epoch_time_sec</td><td>10</td></tr><tr><td>learning_rate</td><td>0.00886</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0.14365</td></tr><tr><td>test_loss</td><td>0.28869</td></tr><tr><td>train_loss</td><td>0.19498</td></tr><tr><td>trainable_parameters</td><td>58290</td></tr><tr><td>valid_accuracy</td><td>0.15014</td></tr><tr><td>valid_loss</td><td>0.28177</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">radiant-sweep-27</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/iqgyxcen' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/iqgyxcen</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_135631-iqgyxcen/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nbx3anqz errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: daekt2n5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003910852536444529\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140256-daekt2n5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/daekt2n5' target=\"_blank\">avid-sweep-28</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/daekt2n5' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/daekt2n5</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.3, 'embedding_size': 32, 'encoder_layers': 1, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.003910852536444529, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 232,498 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"642520ba62e64a25ab4174f565d45d96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f798ba35e14ce6bdc586ee7fe07ebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3218c819858142669da2094a06c9567c"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (2, 128, 128), got [1, 128, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>232498</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">avid-sweep-28</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/daekt2n5' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/daekt2n5</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_140256-daekt2n5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run daekt2n5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (2, 128, 128), got [1, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run qyypo41y errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oipmqf4r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001293942236058646\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140408-oipmqf4r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/oipmqf4r' target=\"_blank\">expert-sweep-30</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/oipmqf4r' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/oipmqf4r</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 2, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.001293942236058646, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 259,634 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e35ac05118944df8dbb5c13eba066e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc9efeb60214533a7034313da55c415"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275ba1f634e74c588f79219db8b5f6cb"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (1, 128, 128), got [2, 128, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>259634</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">expert-sweep-30</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/oipmqf4r' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/oipmqf4r</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_140408-oipmqf4r/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run oipmqf4r errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (1, 128, 128), got [2, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run p2lo6193 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gp1xqc9f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008530254700150846\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140509-gp1xqc9f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/gp1xqc9f' target=\"_blank\">exalted-sweep-32</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/gp1xqc9f' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/gp1xqc9f</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 64, 'encoder_layers': 3, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.008530254700150846, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 358,706 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"220400b321d44a9f82d3fde9f245a619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c27c579ed53542ca96e8643cb862b591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b61375c48bb4c23ad4460a16b8cf7e9"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (1, 128, 128), got [3, 128, 128]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>trainable_parameters</td><td>358706</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">exalted-sweep-32</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/gp1xqc9f' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/gp1xqc9f</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_140509-gp1xqc9f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run gp1xqc9f errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (1, 128, 128), got [3, 128, 128]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 44pu75gd errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c28sxvua with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004205763507118058\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140611-c28sxvua</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/c28sxvua' target=\"_blank\">silver-sweep-34</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/c28sxvua' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/c28sxvua</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.2, 'embedding_size': 128, 'encoder_layers': 2, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0004205763507118058, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0.0001}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 137,906 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3667864f15ab4bbca58679066067ac73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33573753ed164b038d250d2bc28a9d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82b46a1f14c487997e01cd8149b5c23"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 0m 45s\n\tTrain Loss: 0.5772\n\t Val. Loss: 0.5254\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000421\nSaved new best model to best-model-c28sxvua.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc741de9d7d46f1bc5beb252e3bba58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1172b9e0b7c5429486f0291ea6d65850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6db993b660f4c30adef0ea9d06e9d3c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 0m 45s\n\tTrain Loss: 0.5561\n\t Val. Loss: 0.5227\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000421\nSaved new best model to best-model-c28sxvua.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"884bc1e89e354deb9a6ea377ac162703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c361de29064711abeba8a4b53c5838"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534fb2c2d38e434fbc05a0bcdb05b7bb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 0m 45s\n\tTrain Loss: 0.5540\n\t Val. Loss: 0.5217\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000421\nSaved new best model to best-model-c28sxvua.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60a30ee8f4c44d91bde5358eddbea501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7fcde5ca224ebf9cc13f4c2d4a9baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d9487390c9444eabd6d6f28b5dd924"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 0m 45s\n\tTrain Loss: 0.5534\n\t Val. Loss: 0.5215\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000421\nSaved new best model to best-model-c28sxvua.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80eaa48a86b846a9aa79e5fc002241f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7b836e598148d19767a5ac2496a857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ae1fb79d3a45d78d53fc31f765c2ea"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 0m 45s\n\tTrain Loss: 0.5531\n\t Val. Loss: 0.5218\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.000421\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4ae36ca150e4769a32f664b068c7ab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39fcdaeda084c0e924434f092c4db83"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.5267 | Test Accuracy: 0.0000\nSaved predictions to predictions/vanilla/predictions-c28sxvua.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>0</td></tr><tr><td>epoch_time_sec</td><td>45</td></tr><tr><td>learning_rate</td><td>0.00042</td></tr><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>test_accuracy</td><td>0</td></tr><tr><td>test_loss</td><td>0.52673</td></tr><tr><td>train_loss</td><td>0.55307</td></tr><tr><td>trainable_parameters</td><td>137906</td></tr><tr><td>valid_accuracy</td><td>0</td></tr><tr><td>valid_loss</td><td>0.52177</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silver-sweep-34</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/c28sxvua' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/c28sxvua</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_140611-c28sxvua/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c60djjw4 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l8jshma4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011274310666666168\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_141025-l8jshma4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/l8jshma4' target=\"_blank\">fiery-sweep-36</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/l8jshma4' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/l8jshma4</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 32, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.2, 'embedding_size': 128, 'encoder_layers': 1, 'hidden_size': 256, 'language': 'ta', 'learning_rate': 0.0011274310666666168, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 813,618 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe91a49c02f24baaa63bdf1d87f3ad5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3579378e8b04433aad985aca819fa3ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"636b02c5f50447c196b1ad0e243e0054"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 2m 37s\n\tTrain Loss: 0.4771\n\t Val. Loss: 0.5657\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001127\nSaved new best model to best-model-l8jshma4.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecd2f0ec7334485a14acd261bb3fe1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf0f82f7bab4cfc8e605ae81f2e8cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f4420b56174f729a1457e198e32922"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 2m 38s\n\tTrain Loss: 0.4244\n\t Val. Loss: 0.5772\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b09ec79f33c424abb06dc4e32fe8d5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02651d6615e747ac83a9d5ea3271f5bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7074b011f745668f6b545e36061042"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 2m 37s\n\tTrain Loss: 0.3246\n\t Val. Loss: 0.4345\n\t Val. Accuracy: 0.0217\n\t Learning Rate: 0.001127\nSaved new best model to best-model-l8jshma4.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53fce266a01d4d5c8fa1f1285a7f7acf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec97a4a6bdb4340bf031762e4abb3be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f13cb1eca345c886f93fa467d2adc1"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 2m 38s\n\tTrain Loss: 0.2096\n\t Val. Loss: 0.3424\n\t Val. Accuracy: 0.1336\n\t Learning Rate: 0.001127\nSaved new best model to best-model-l8jshma4.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c0f6faefed4368a23d80323ea54491"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1920647571a74dc4a9cf377c8aba3b60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/214 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03306e7ae6f044449a889eccfc605d25"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 2m 37s\n\tTrain Loss: 0.1456\n\t Val. Loss: 0.2862\n\t Val. Accuracy: 0.2329\n\t Learning Rate: 0.001127\nSaved new best model to best-model-l8jshma4.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"772588717fee47ea9eac1b6b56a99a15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/215 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d4e3eda5ce44a884f90b88a1a327cd"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.3000 | Test Accuracy: 0.2284\nSaved predictions to predictions/vanilla/predictions-l8jshma4.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch_time_min</td><td>▁▁▁▁▁</td></tr><tr><td>epoch_time_sec</td><td>▁█▁█▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▂▁</td></tr><tr><td>trainable_parameters</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁▁▂▅█</td></tr><tr><td>valid_loss</td><td>██▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>epoch_time_min</td><td>2</td></tr><tr><td>epoch_time_sec</td><td>37</td></tr><tr><td>learning_rate</td><td>0.00113</td></tr><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>test_accuracy</td><td>0.22844</td></tr><tr><td>test_loss</td><td>0.29997</td></tr><tr><td>train_loss</td><td>0.14559</td></tr><tr><td>trainable_parameters</td><td>813618</td></tr><tr><td>valid_accuracy</td><td>0.2329</td></tr><tr><td>valid_loss</td><td>0.28625</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-sweep-36</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/l8jshma4' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/l8jshma4</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_141025-l8jshma4/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ka5lylte errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i9c0nfkt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0022867987141504203\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_142407-i9c0nfkt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/i9c0nfkt' target=\"_blank\">brisk-sweep-15</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/i9c0nfkt' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/i9c0nfkt</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 2, 'dropout': 0.2, 'embedding_size': 128, 'encoder_layers': 1, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0022867987141504203, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 112,946 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f02c97ec4ac4d32ace4c8bfd78fd871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b868f0ea2a64af7bc98b60ed7fb2b00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35d0331519b47cba1e34866942264c3"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n    decoder_output, hidden, _ = model.decoder(\n                                ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n    output, hidden = self.rnn(embedded, hidden)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n    self.check_hidden_size(hidden, expected_hidden_size)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden size (2, 128, 64), got [1, 128, 64]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>adam</td></tr><tr><td>trainable_parameters</td><td>112946</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">brisk-sweep-15</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/i9c0nfkt' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/i9c0nfkt</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_142407-i9c0nfkt/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run i9c0nfkt errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 194, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, _ = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                 ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 100, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, hidden = self.rnn(embedded, hidden)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1391, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 366, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(hidden, expected_hidden_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden size (2, 128, 64), got [1, 128, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run vi8pw8ba errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h6iao8jo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005235623740148747\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: none\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_142518-h6iao8jo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/h6iao8jo' target=\"_blank\">fast-sweep-38</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/h6iao8jo' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/h6iao8jo</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 64, 'cell_type': 'lstm', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.3, 'embedding_size': 128, 'encoder_layers': 3, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.005235623740148747, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'rmsprop', 'scheduler': 'none', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 179,378 trainable parameters\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1066 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f7f162d099b48328a8802ec698b5bce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6471e1d7a494a3b8fc9fe612b48971b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/107 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"818547a66d834d7fb8b0c1eb96fba855"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n    valid_accuracy, _ = calculate_accuracy(\n                        ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n    decoder_output, hidden, cell = model.decoder(\n                                   ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n    self.check_forward_args(input, hx, batch_sizes)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n    self.check_hidden_size(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\nRuntimeError: Expected hidden[0] size (1, 64, 64), got [3, 64, 64]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainable_parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>optimizer_type</td><td>rmsprop</td></tr><tr><td>trainable_parameters</td><td>179378</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fast-sweep-38</strong> at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/h6iao8jo' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/h6iao8jo</a><br> View project at: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_142518-h6iao8jo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run h6iao8jo errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2448685418.py\", line 191, in train_model\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     valid_accuracy, _ = calculate_accuracy(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                         ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/7560943.py\", line 190, in calculate_accuracy\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     decoder_output, hidden, cell = model.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3382890687.py\", line 96, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1120, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 1003, in check_forward_args\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.check_hidden_size(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\", line 347, in check_hidden_size\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected hidden[0] size (1, 64, 64), got [3, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run dui6c8hx errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 300, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb.teardown()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.11/contextlib.py\", line 81, in inner\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwds)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 404, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     orig_singleton._teardown(exit_code=exit_code)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\", line 249, in _teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     internal_exit_code = self._connection.teardown(exit_code or 0)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/service_connection.py\", line 212, in teardown\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise WandbServiceNotOwnedError(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.lib.service_connection.WandbServiceNotOwnedError: Cannot tear down service started by different process\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lzbp2rn9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlanguage: ta\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0013674929836985695\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_seq_len: 50\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: plateau\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'transliteration-seq2seq' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_142655-lzbp2rn9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/lzbp2rn9' target=\"_blank\">solar-sweep-39</a></strong> to <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/sweeps/mbrh064k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/lzbp2rn9' target=\"_blank\">https://wandb.ai/teja_sai-indian-institute-of-technology-madras/transliteration-seq2seq/runs/lzbp2rn9</a>"},"metadata":{}},{"name":"stdout","text":"Starting training run with config: {'batch_size': 128, 'cell_type': 'gru', 'clip': 1, 'decoder_layers': 1, 'dropout': 0.3, 'embedding_size': 64, 'encoder_layers': 1, 'hidden_size': 64, 'language': 'ta', 'learning_rate': 0.0013674929836985695, 'max_seq_len': 50, 'n_epochs': 5, 'optimizer': 'adam', 'scheduler': 'plateau', 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0}\nLooking for training file at: /kaggle/input/dakshina-dataset-v1-0-tar/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\nSpecial tokens in vocabulary:\nSource vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']\nTarget vocab keys: ['<PAD>', '<UNK>', '<SOS>', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']\nSuccessfully loaded Dakshina dataset for ta\nTrain set: 68218 examples\nDev set: 6827 examples\nTest set: 6864 examples\nSource vocabulary size: 30\nTarget vocabulary size: 50\nMax sequence length: 50\nUsing device: cuda\nThe model has 58,290 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a66adcfc6f0467c81279d2689c1be98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577b6debc1a14bbab6109ef9ffd082e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03dcbbd2de84b77bd748fbd72ffe4df"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 0m 37s\n\tTrain Loss: 0.5545\n\t Val. Loss: 0.5449\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001367\nSaved new best model to best-model-lzbp2rn9.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57e87b17b3c494f903c73877e28ab4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63e76f3cf5e34334819f1058c66c760c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f3b65aca7c94f92a7a9502696cf9546"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 0m 38s\n\tTrain Loss: 0.4646\n\t Val. Loss: 0.5180\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001367\nSaved new best model to best-model-lzbp2rn9.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6fe952507a45feb776a563cfd2d8c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62707e889ab4acb9eaabd567300f10e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6103f118b304c4db446f5e4d1ed490c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 0m 37s\n\tTrain Loss: 0.4353\n\t Val. Loss: 0.5053\n\t Val. Accuracy: 0.0000\n\t Learning Rate: 0.001367\nSaved new best model to best-model-lzbp2rn9.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29cf02bf59044ed7b7be44d5928f2751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d9465009c7e4bcd81a52833d7ec8b0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add0c32aaf124b8181b4041b37c5ff40"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 0m 38s\n\tTrain Loss: 0.4035\n\t Val. Loss: 0.4921\n\t Val. Accuracy: 0.0006\n\t Learning Rate: 0.001367\nSaved new best model to best-model-lzbp2rn9.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/533 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a47905acc9441ca721fe7198efff5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc69e75d15b745c8af79518cd60121f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Calculating Accuracy:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604fea99a96e4e71beb6f503f40f362b"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05 | Time: 0m 37s\n\tTrain Loss: 0.3800\n\t Val. Loss: 0.4735\n\t Val. Accuracy: 0.0007\n\t Learning Rate: 0.001367\nSaved new best model to best-model-lzbp2rn9.pt\nTraining finished.\nEvaluating best model on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Loss:   0%|          | 0/54 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127bbad83ebb4eaea4eacb4019ef76b2"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}