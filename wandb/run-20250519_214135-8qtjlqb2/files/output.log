Starting training run with config: {'batch_size': 64, 'cell_type': 'lstm', 'clip': 1, 'data_dir': '../dakshina_dataset_v1.0', 'decoder_layers': 2, 'dropout': 0, 'embedding_size': 64, 'encoder_layers': 2, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.0005, 'max_seq_len': 50, 'n_epochs': 15, 'teacher_forcing_ratio': 0.5, 'use_attention': False}
Attempting to load data from: ../dakshina_dataset_v1.0\ta\lexicons\ta.translit.sampled.train.tsv, ../dakshina_dataset_v1.0\ta\lexicons\ta.translit.sampled.dev.tsv, ../dakshina_dataset_v1.0\ta\lexicons\ta.translit.sampled.test.tsv
Error: Training file not found at ../dakshina_dataset_v1.0\ta\lexicons\ta.translit.sampled.train.tsv
Current working directory: C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3
Falling back to creating a small test dataset for debugging.
Creating a minimal test dataset for debugging...
Created minimal test dataset with:
Train set: 2 examples
Dev set: 1 examples
Test set: 1 examples
Source vocabulary size: 15
Target vocabulary size: 20
Max sequence length: 50
Using device: cuda
The model has 467,668 trainable parameters
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 14.26it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 183.53it/s]
Epoch: 01 | Time: 0m 0s
	Train Loss: 2.9957
	 Val. Loss: 2.9957
	 Val. Accuracy: 0.0000
Saved new best model to best-model-8qtjlqb2.pt
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.99it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 14.58it/s]
Calculating Accuracy: 100%|██████████████████████████████| 1/1 [00:00<00:00, 98.88it/s]
Epoch: 02 | Time: 0m 0s
	Train Loss: 2.9951
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.74it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 20.06it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 186.66it/s]
Epoch: 03 | Time: 0m 0s
	Train Loss: 2.9943
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.05it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 20.81it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 187.09it/s]
Epoch: 04 | Time: 0m 0s
	Train Loss: 2.9934
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.06it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 21.66it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 173.94it/s]
Epoch: 05 | Time: 0m 0s
	Train Loss: 2.9925
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.97it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 22.87it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 190.45it/s]
Epoch: 06 | Time: 0m 0s
	Train Loss: 2.9914
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.05it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 22.93it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 161.45it/s]
Epoch: 07 | Time: 0m 0s
	Train Loss: 2.9902
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 21.45it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 124.80it/s]
Epoch: 08 | Time: 0m 0s
	Train Loss: 2.9891
	 Val. Loss: 2.9958
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.68it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 21.16it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 156.77it/s]
Epoch: 09 | Time: 0m 0s
	Train Loss: 2.9876
	 Val. Loss: 2.9959
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.03it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 21.91it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 187.46it/s]
Epoch: 10 | Time: 0m 0s
	Train Loss: 2.9855
	 Val. Loss: 2.9959
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.15it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 22.56it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 163.47it/s]
Epoch: 11 | Time: 0m 0s
	Train Loss: 2.9835
	 Val. Loss: 2.9959
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  4.92it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 22.27it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 191.96it/s]
Epoch: 12 | Time: 0m 0s
	Train Loss: 2.9811
	 Val. Loss: 2.9959
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 23.36it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 119.09it/s]
Epoch: 13 | Time: 0m 0s
	Train Loss: 2.9782
	 Val. Loss: 2.9959
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.10it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 22.64it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 170.59it/s]
Epoch: 14 | Time: 0m 0s
	Train Loss: 2.9748
	 Val. Loss: 2.9960
	 Val. Accuracy: 0.0000
Training: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.06it/s]
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 20.55it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 187.70it/s]
Epoch: 15 | Time: 0m 0s
	Train Loss: 2.9706
	 Val. Loss: 2.9960
	 Val. Accuracy: 0.0000
Training finished.
Evaluating best model on test set...
C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3\src\training\train.py:265: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(model_save_path))
Evaluating: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 23.45it/s]
Calculating Accuracy: 100%|█████████████████████████████| 1/1 [00:00<00:00, 173.48it/s]
Test Loss: 2.9956 | Test Accuracy: 0.0000
Saved predictions to predictions/vanilla/predictions-8qtjlqb2.json
