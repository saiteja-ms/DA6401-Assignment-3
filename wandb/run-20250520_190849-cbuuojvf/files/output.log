Starting training run with config: {'batch_size': 32, 'cell_type': 'lstm', 'clip': 1, 'data_dir': '.', 'dropout': 0, 'embedding_size': 128, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.0004687611612460029, 'max_seq_len': 50, 'momentum': 0, 'n_epochs': 20, 'num_layers': 3, 'optimizer': 'adam', 'rmsprop_alpha': 0.99, 'scheduler': 'plateau', 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'scheduler_t_max': 20, 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'weight_decay': 0.0001}
Looking for training file at: .\ta\lexicons\ta.translit.sampled.train.tsv
Special tokens in vocabulary:
Source vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']
Target vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']
Successfully loaded Dakshina dataset for ta
Train set: 68218 examples
Dev set: 6827 examples
Test set: 6864 examples
Source vocabulary size: 30
Target vocabulary size: 50
Max sequence length: 50
Using device: cuda
The model has 809,266 trainable parameters
C:\Users\DELL\anaconda3\envs\Transliteration\lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2132/2132 [05:32<00:00,  6.42it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:07<00:00, 30.55it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:03<00:00, 70.21it/s]
Epoch: 01 | Time: 5m 42s
	Train Loss: 0.5648
	 Val. Loss: 0.5232
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Saved new best model to best-model-cbuuojvf.pt
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2132/2132 [05:42<00:00,  6.22it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:07<00:00, 27.73it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:03<00:00, 64.94it/s]
Epoch: 02 | Time: 5m 53s
	Train Loss: 0.5539
	 Val. Loss: 0.5228
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Saved new best model to best-model-cbuuojvf.pt
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2132/2132 [06:28<00:00,  5.49it/s]
Evaluating Loss: 100%|███████████████████████████████| 214/214 [00:08<00:00, 25.09it/s]
Calculating Accuracy: 100%|██████████████████████████| 214/214 [00:03<00:00, 54.54it/s]
Epoch: 03 | Time: 6m 40s
	Train Loss: 0.5535
	 Val. Loss: 0.5218
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Saved new best model to best-model-cbuuojvf.pt
Training: 100%|████████████████████████████████████| 2132/2132 [06:28<00:00,  5.49it/s]
Evaluating Loss: 100%|████████| 214/214 [00:07<00:00, 27.99it/s]
Calculating Accuracy: 100%|███| 214/214 [00:04<00:00, 50.69it/s]
Epoch: 04 | Time: 6m 40s
	Train Loss: 0.5533
	 Val. Loss: 0.5226
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Training: 100%|█████████████| 2132/2132 [06:29<00:00,  5.47it/s]
Evaluating Loss: 100%|████████| 214/214 [00:08<00:00, 24.52it/s]
Calculating Accuracy: 100%|███| 214/214 [00:03<00:00, 60.37it/s]
Epoch: 05 | Time: 6m 42s
	Train Loss: 0.5531
	 Val. Loss: 0.5229
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Training: 100%|█████████████| 2132/2132 [06:21<00:00,  5.58it/s]
Evaluating Loss: 100%|███████████████████████████████| 214/214 [00:08<00:00, 25.59it/s]
Calculating Accuracy: 100%|██████████████████████████| 214/214 [00:03<00:00, 59.07it/s]
Epoch: 06 | Time: 6m 33s
	Train Loss: 0.5530
	 Val. Loss: 0.5223
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Training: 100%|████████████████████████████████████| 2132/2132 [08:07<00:00,  4.37it/s]
Evaluating Loss: 100%|███████████████████████████████| 214/214 [00:11<00:00, 19.42it/s]
Calculating Accuracy: 100%|██████████████████████████| 214/214 [00:05<00:00, 38.59it/s]
Epoch: 07 | Time: 8m 24s
	Train Loss: 0.5531
	 Val. Loss: 0.5220
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000469
Training:  20%|███████▍                             | 432/2132 [01:47<05:44,  4.93it/s]
