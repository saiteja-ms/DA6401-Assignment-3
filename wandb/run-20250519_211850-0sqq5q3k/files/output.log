Starting training run with config: {'language': 'ta', 'embedding_size': 64, 'hidden_size': 128, 'encoder_layers': 1, 'decoder_layers': 1, 'cell_type': 'lstm', 'dropout': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'n_epochs': 20, 'clip': 1.0, 'teacher_forcing_ratio': 0.5, 'use_attention': False, 'data_dir': 'ta', 'max_seq_len': 50}
Attempting to load data from: ta\ta\lexicons\ta.translit.sampled.train.tsv, ta\ta\lexicons\ta.translit.sampled.dev.tsv, ta\ta\lexicons\ta.translit.sampled.test.tsv
Error: Training file not found at ta\ta\lexicons\ta.translit.sampled.train.tsv
Current working directory: C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3
Falling back to creating a small test dataset for debugging.
Creating a minimal test dataset for debugging...
Created minimal test dataset with:
Train set: 2 examples
Dev set: 1 examples
Test set: 1 examples
Source vocabulary size: 15
Target vocabulary size: 20
Max sequence length: 50
Using device: cuda
The model has 203,476 trainable parameters
Training:   0%|                                                  | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3\src\training\train.py", line 217, in train_model
    train_loss = train_epoch(
  File "C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3\src\training\train.py", line 81, in train_epoch
    output = output[batch_size:]
NameError: name 'batch_size' is not defined
