Starting training run with config: {'batch_size': 64, 'cell_type': 'gru', 'clip': 1, 'data_dir': '.', 'dropout': 0.3, 'embedding_size': 64, 'hidden_size': 128, 'language': 'ta', 'learning_rate': 0.00013164117505872733, 'max_seq_len': 50, 'momentum': 0.9, 'n_epochs': 20, 'num_layers': 2, 'optimizer': 'adam', 'rmsprop_alpha': 0.99, 'scheduler': 'none', 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'scheduler_t_max': 20, 'teacher_forcing_ratio': 0.7, 'use_attention': False, 'weight_decay': 0.001}
Looking for training file at: .\ta\lexicons\ta.translit.sampled.train.tsv
Special tokens in vocabulary:
Source vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'a', 'b', 'c', 'd', 'e', 'f']
Target vocab keys: ['<PAD>', '<UNK>', '< SOS >', '<EOS>', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ']
Successfully loaded Dakshina dataset for ta
Train set: 68218 examples
Dev set: 6827 examples
Test set: 6864 examples
Source vocabulary size: 30
Target vocabulary size: 50
Max sequence length: 50
Using device: cuda
The model has 358,706 trainable parameters
Training: 100%|████████████████████████████████████| 1066/1066 [02:41<00:00,  6.59it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 30.27it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 45.42it/s]
Epoch: 01 | Time: 2m 47s
	Train Loss: 0.6003
	 Val. Loss: 0.5379
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:36<00:00,  6.83it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 30.12it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 39.87it/s]
Epoch: 02 | Time: 2m 42s
	Train Loss: 0.5629
	 Val. Loss: 0.5287
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:35<00:00,  6.86it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 29.97it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 43.67it/s]
Epoch: 03 | Time: 2m 41s
	Train Loss: 0.5582
	 Val. Loss: 0.5266
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:40<00:00,  6.63it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 30.39it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 40.64it/s]
Epoch: 04 | Time: 2m 47s
	Train Loss: 0.5569
	 Val. Loss: 0.5257
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:28<00:00,  7.17it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:04<00:00, 25.77it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:03<00:00, 33.92it/s]
Epoch: 05 | Time: 2m 35s
	Train Loss: 0.5563
	 Val. Loss: 0.5256
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:38<00:00,  6.70it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 30.82it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 44.67it/s]
Epoch: 06 | Time: 2m 44s
	Train Loss: 0.5561
	 Val. Loss: 0.5254
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:40<00:00,  6.66it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 31.18it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 43.31it/s]
Epoch: 07 | Time: 2m 45s
	Train Loss: 0.5559
	 Val. Loss: 0.5252
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|████████████████████████████████████| 1066/1066 [02:35<00:00,  6.86it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:03<00:00, 30.72it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:02<00:00, 46.41it/s]
Epoch: 08 | Time: 2m 41s
	Train Loss: 0.5557
	 Val. Loss: 0.5246
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Saved new best model to best-model-ldx89m0n.pt
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1066/1066 [02:35<00:00,  6.87it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:03<00:00, 30.83it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:02<00:00, 40.42it/s]
Epoch: 09 | Time: 2m 41s
	Train Loss: 0.5558
	 Val. Loss: 0.5248
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1066/1066 [02:37<00:00,  6.76it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 27.18it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 39.70it/s]
Epoch: 10 | Time: 2m 44s
	Train Loss: 0.5556
	 Val. Loss: 0.5247
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [03:16<00:00,  5.42it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:06<00:00, 16.09it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:04<00:00, 21.85it/s]
Epoch: 11 | Time: 3m 28s
	Train Loss: 0.5556
	 Val. Loss: 0.5249
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [03:42<00:00,  4.78it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:06<00:00, 17.27it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:05<00:00, 20.45it/s]
Epoch: 12 | Time: 3m 54s
	Train Loss: 0.5557
	 Val. Loss: 0.5254
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [04:04<00:00,  4.36it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:05<00:00, 18.40it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:04<00:00, 23.45it/s]
Epoch: 13 | Time: 4m 14s
	Train Loss: 0.5556
	 Val. Loss: 0.5251
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [05:11<00:00,  3.42it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 32.98it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 48.58it/s]
Epoch: 14 | Time: 5m 16s
	Train Loss: 0.5556
	 Val. Loss: 0.5247
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [02:31<00:00,  7.03it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:04<00:00, 25.68it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 45.11it/s]
Epoch: 15 | Time: 2m 38s
	Train Loss: 0.5555
	 Val. Loss: 0.5249
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [02:37<00:00,  6.76it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:04<00:00, 25.81it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 45.16it/s]
Epoch: 16 | Time: 2m 44s
	Train Loss: 0.5554
	 Val. Loss: 0.5248
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [02:46<00:00,  6.39it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 26.83it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 36.22it/s]
Epoch: 17 | Time: 2m 53s
	Train Loss: 0.5556
	 Val. Loss: 0.5250
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [02:49<00:00,  6.29it/s]
Evaluating Loss: 100%|███████████████████████████████| 107/107 [00:03<00:00, 28.44it/s]
Calculating Accuracy: 100%|██████████████████████████| 107/107 [00:02<00:00, 43.63it/s]
Epoch: 18 | Time: 2m 55s
	Train Loss: 0.5555
	 Val. Loss: 0.5251
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|████████████████████████████████████| 1066/1066 [02:38<00:00,  6.73it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:03<00:00, 28.92it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:02<00:00, 39.43it/s]
Epoch: 19 | Time: 2m 44s
	Train Loss: 0.5555
	 Val. Loss: 0.5255
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1066/1066 [02:32<00:00,  6.98it/s]
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:03<00:00, 30.43it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:02<00:00, 47.13it/s]
Epoch: 20 | Time: 2m 38s
	Train Loss: 0.5555
	 Val. Loss: 0.5248
	 Val. Accuracy: 0.0000
	 Learning Rate: 0.000132
Training finished.
Evaluating best model on test set...
C:\Users\DELL\Documents\SEMESTER 8\Deep Learning\Assignment_3\DA6401-Assignment-3\src\training\train.py:308: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(model_save_path, map_location=device))
Evaluating Loss: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:03<00:00, 30.90it/s]
Calculating Accuracy: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:02<00:00, 47.10it/s]
Test Loss: 0.5279 | Test Accuracy: 0.0000
Saved predictions to predictions/vanilla/predictions-ldx89m0n.json
