{
    "language": "ta",
    "embedding_size": 64,
    "hidden_size": 128,
    "encoder_layers": 1,
    "decoder_layers": 1,
    "cell_type": "lstm",
    "dropout": 0.2,
    "learning_rate": 0.001,
    "batch_size": 64,
    "n_epochs": 20,
    "clip": 1.0,
    "teacher_forcing_ratio": 0.5,
    "use_attention": false
}
