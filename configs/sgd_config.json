{
    "language": "ta",
    "embedding_size": 64,
    "hidden_size": 128,
    "encoder_layers": 1,
    "decoder_layers": 1,
    "cell_type": "lstm",
    "dropout": 0.2,
    "learning_rate": 0.01,
    "batch_size": 64,
    "n_epochs": 25,
    "clip": 1.0,
    "teacher_forcing_ratio": 0.5,
    "use_attention": false,
    "max_seq_len": 50,
    "optimizer": "sgd",
    "momentum": 0.9,
    "weight_decay": 0.0001,
    "scheduler": "cosine",
    "scheduler_t_max": 25,
    "scheduler_eta_min": 0.0001
}
